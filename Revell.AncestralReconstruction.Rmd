---
title: "Ancestral Reconstruction: Theory & Practice"
authors:
  - name: Liam J. Revell
    department: Department of Biology
    affiliation: University of Massachusetts Boston
    location: Boston, MA 02125
    email: liam.revell@umb.edu
abstract: |
  Ancestral state reconstruction involves estimating the unknown trait values of hypothetical ancestral species at internal nodes of a phylogenetic tree. In this Chapter, I'll briefly illustrate the theory and practice of ancestral state reconstruction for both discrete and continuously-valued character traits, highlight several use cases \emph{via} a set of empirical examples, and discuss the statistical properties of ancestral state estimation as well as some of its limitations.
header-includes: |
    \usepackage{amsmath,mathtools,bm,nicematrix}
bibliography: references.bib
biblio-style: unsrt
output:
  bookdown::pdf_book:
    base_format: rticles::arxiv_article
csl: evolution.csl
nocite: |
  @Walker2012; @Yaxley2019; @Li2022, @Nielsen2002, @Hall2018
---

```{r, echo=FALSE, results="hide", message=FALSE}
library(phytools)
library(expm)
```
# Introduction

Ancestral state reconstruction\footnote{Ancestral state reconstruction is also often referred to as \emph{ancestral character estimation}. These are the same thing, and I'll use the two terms interchangeably here.} is the general practice of estimating the value or values of a feature or attribute at the set of common ancestors of the operational taxa\footnote{Operational taxa are the named tips or leaves in a reconstructed phylogenetic tree. In many studies using phylogenetic comparative methods, operational taxa are nominal species, but they could also be subspecies, populations, cultural groups (in the case of language phylogenies), genera, or other units of study (e.g., Walker et al. 2012; Hall et al. 2018; Yaxley and Foley 2019; Li et al. 2022).} of a phylogenetic tree [@Schluter1997; @Yang2006-book; @Yang2014-book; @Revell2022-book]. Ancestral state reconstruction falls within the domain of phylogenetic comparative methods\footnote{For the purposes of this Chapter, phylogenetic comparative methods are the set of methodologies that are used (typically) \emph{downstream} of phylogenetic inference to test hypotheses about evolution based on a tree, and often in combination with trait data for the terminal taxa of that tree.} [@Pagel1997; @Nunn2011-book; @OMeara2012; @Harmon2019-book; @Revell2022-book], and has long been relentlessly popular. The popularity of ancestral reconstruction is easy to comprehend. Evolutionary biologists are often inherently interested in the evolutionary past, and ancestral character estimation promises us a window towards that otherwise invisible history [@Revell2022-book].

Undertaking ancestral state reconstruction requires that we have a reconstructed tree\footnote{Or set of trees, e.g., from a bootstrapping analysis or Bayesian posterior sample.}\textsuperscript{,}\footnote{None of the methods of this chapter technically require that our input tree be ultrametric or time-calibrated. Normally, however, I recommend using an ultrametric or time-calibrated tree unless we have a formal, \emph{a priori} hypothesis that the rate of evolution of our trait is better predicted by non-ultrametric branch lengths -- for instance the branch lengths obtained from Maximum Likelihood phylogeny inference -- than by units of chronological time. The circumstances in which this is true are, I believe, quite rare.}, as well as observations of a phenotypic trait of interest from some or all of the terminal taxa of that tree [@Nunn2011-book; @Revell2022-book]. Modern ancestral state reconstruction also requires that we have a model or hypothesized model for how our character trait evolved over the macroevolutionary time represented by our phylogeny.\footnote{At the risk of upsetting some enthusiasts, and apart from in this footnote, I will avoid discusing \emph{parsimony} as a procedure of ancestral state reconstruction here. Parsimony, better known as a technique of phylogeny inference, is a procedure whereby we seek to identify the set of ancestral states that will minimize the minimum number of evolutionary changes in our character that are required to explain the observed data pattern. This set of node values can then be characterized as the \emph{maximum parsimony} or \emph{most parsimonious} ancestral states. Even though this might seem sensible and will often provide very reasonable ancestral character estimates, parsimony leaves us with substantial difficulty in assessing the strength of evidence in support of this most parsimonious solution -- compared to, say, an alternative only slightly less parsimonious one -- and does not provide any firm criteria for averaging across any equally parsimonious sets of states. For this reason, and others, I have decided to focus on explicit, probabilistic procedures of ancestral state inference in this chapter.} Finally, we'll use a formal statistical inference procedure to obtain a set of estimates of our trait at some or all of the internal nodes of the tree.

In the sections below, I'll first offer some preliminaries on the goals of this chapter and on terminology. I'll then proceed to describe the procedures for estimating ancestral phenotypes, first for discrete and then for continuously-valued traits, accompanying each section with a small number of empirical examples. Finally, I'll discuss some limitations of ancestral state estimation, focusing particularly on those arising from identifiable inadequacies of the assumed trait evolution model.

# Preliminaries

This chapter focuses on phylogenetic ancestral state reconstruction of discrete and continuously-valued phenotypic traits. A phylogenetic tree is a acyclic\footnote{Acyclic just means that the graph doesn't form loops or cycles.}, directed graph, typically used as a model to represent the historical relationships among species unified by common descent [@Felsenstein2004-book; @Yang2014-book; @Revell2022-book]. Phylogenies are also used to approximate other entities connected via a similar form of ancestor-descendant relationship, such as human cultural groups, viral sequences of an emerging infectious disease, or metastatic tumor cell lines in a cancer patient [e.g., @Gray2009; @Nunn2011-book; @Somarelli2017; @Turakhia2020; @Quinn2021].

Phylogenies consist of three main components: nodes, branches, and tips [@Yang2006-book; @Baum2012-book; @Revell2022-book]. Nodes are hypothetical ancestral taxa located at the nexus point of two or more descendant branches. A branch (often referred to as an *edge*, and I'll use the terms interchangeably here)\footnote{Branch is the term that predominates in the phylogenetic literature, whereas edge is used more commonly by biomathematicians and graph theoreticians.} is a connection between two different nodes: parent (i.e., ancestral) and daughter (i.e, descendant). Branches often have the property of length, which, in the type of tree used for ancestral state reconstruction, often represents elapsed time in some unit. Finally, a tip (often referred to as a *leaf*, and I'll sometimes use that term here) is an external node of the tree, not connected to any descendant nodes, that is used to represent a species or other operational taxon of the phylogeny. Once again, in the type of phylogenetic tree used for ancestral state reconstruction, tips most often have as an attribute a label, indicating to which taxon they correspond [@Felsenstein2004-book; @Baum2012-book].

Though ancestral state reconstruction can also be undertaken for nucleotide sequence or other molecular characters [e.g., @Yang2014-book], in this chapter I'll focus on ancestral state reconstruction of phenotypic traits [@Schluter1997; @Nunn2011-book; @Revell2022-book]. A phenotypic trait is an observable attribute -- be it physical, morphological, behavioral, ecological, physiological, cellular, etc. -- of the operational taxa of the tree. In the field of phylogenetic comparative biology, we conventionally subdivide phenotypic traits into two general categories (whilst realizing that some traits may not fall neatly into either): discrete and continuous [@Pagel1997; @Felsenstein2004-book; @Revell2022-book; @Revell2024]. 

Discrete characters are phenotypic attributes that can only assume one of fixed and finite set of values [@Revell2022-book]. These might range from a discretely-categorized ecological trait [e.g., marine vs. freshwater habitat use in fishes, @BetancurR2015], to a counted meristic character [e.g., pre-caudal vertebra number in primates, @Spear2023], to a behavioral specialization [e.g., diel activity pattern in vertebrates, @Anderson2017], to a categorical physical attribute [e.g., carotenoid-pigmented feathers in birds, @Thomas2014].

Continuous characters, on the other hand, are phenotypic traits that can assume any of an infinite number of values on a real number scale [@Revell2022-book]. Continuous characters needn't be *unbounded* -- for example, a continuous character is often bounded on the lower end by the value of zero. Nonetheless, unbounded evolution is a frequent assumption of continuous character models in phylogenetic comparative analysis [but see @Boucher2016].\footnote{A continuous trait, such as body size, that is bounded on the lower end by zero can often be transformed to an unbounded scale by computing the logarithm. Indeed, this is a common practice for continuous traits in phylogenetic comparative biology.} A continuous trait might range from a linearly measured morphological feature [e.g., orbit size in extant and extinct cetaceans, @Churchill2021], to a mass or volume [e.g., encephalization in birds, @MarugnLobn2021], to a continuously-varying life history trait [e.g., average gestational length in mammals, @Danis2023], even to a molecular genomic attribute [e.g., genome size in plants, @Wang2021].

Our distinction between discrete or continuous characters seems relatively clear when put forward in this manner. Nonetheless, as previously alluded, it may not always be straightforward to decide *a priori* whether a character should be coded as discretely or continuously-valued. For example, plumage color could be quantified numerically using a reflectance spectrometer or scored discretely against a palette containing a finite number of elements [e.g., @DurnCastillo2021]. A meristic (counted) trait might differ discontinuously from individual to individual, but vary intraspecifically such that among-species differences are better-approximated as a continuous random variable than placed in discrete bins. The position of this chapter is that the best way to reconcile this paradox, and contemplate whether a character trait should be categorized as discrete or continuous, is to consider the decision to be an implicit component of our model: in other words, as a necessary approximation of reality. If our trait varies in a manner that is closer to discontinuous than continuous, then (as a model approximation) treating it as discretely-valued is probably most appropriate! Logically, the converse will also be true.

# Discrete characters

## The M*k* model

The standard model used to study the evolution of discrete characters, and thus to reconstruct their ancestral values, is one that's popularly known as the M*k* model [@Pagel1994; @Pagel1997; @Lewis2001; @Harmon2019-book]. This model describes a continuous time Markov chain (the 'M' in M*k*) with *k* possible states [@Revell2022-book]. This M*k* stochastic process is fully parameterized by a $k \times k$ matrix, **Q**, in which all non-diagonal elements of the matrix ($q_{i,j}$ for any $i \ne j$) give the instantaneous transition rates between states *i* and *j*, while the diagonal elements are equal to the negative off-diagonal row sums such that each row of the **Q** matrix adds to zero. An example value of **Q** for a binary discrete character is given below.

$$\mathbf{Q} = \begin{bmatrix}-q_{0,1} & q_{0,1} \\ q_{1,0} & -q_{1,0}\end{bmatrix} = \begin{bmatrix}-0.2 & 0.2\\ 0.2 & -0.2\end{bmatrix}$$

In this **Q** matrix the instantaneous forward and backward rates of transition between the two different levels of our character, 0 and 1, are $q_{0,1} = q_{1,0} = 0.2$.\footnote{For this example \textbf{Q} is symmetric to simplify subsequent calculations -- but it needn't be as a general rule! Indeed, many biological processes predict an asymmetry of backward and forward transition rates between character levels, and this is a common observation of empirical studies.} This value, $q_{0,1} = q_{1,0} = 0.2$, is a *rate* of change in the character under our modeled stochastic process -- meaning that, on average, 0.2 changes of our trait would be expected to occur every time interval.\footnote{Likewise, five time units are expected to be required (on average) for a single change in the character to occur.} The waiting times between events under this continuous-time process will have an exponential distribution with a shape parameter determined by $q_{0,1}$ and $q_{1,0}$, and the probability that (after some time) a change *has* occurred can be computed by integrating this distribution. Indeed, the matrix of probabilities (as opposed to rates) that, after any arbitrary interval of time (given by *t*), our Markov process that began in state *i* is now found in condition *j* is calculable as the simple matrix exponential of $\mathbf{Q} \times t$ [@Pagel1997; @Lewis2001; @Harmon2019-book].

$$\mathbf{P}_t = \exp(\mathbf{Q}t)$$

Here, each element of $\mathbf{P}_t$ ($p_{i,j}$ for all *i* and *j*) gives the probability $P(j|i,t)$: in other words, the chances of being found in state *j* after time *t* having started the time interval in condition *i*.

```{r fig1, echo=FALSE, fig.width=4, fig.height=2.5, dpi=300, fig.cap="A simple, three-taxon, rooted phylogeny with two trait values of a discrete character (0 and 1) mapped at the tips of the tree. The two nodes of the tree (labeled \\emph{root} and \\emph{internal}, respectively) in whose states we might be interested in are indicated on the figure, as are the lengths of the four branches of the tree. See main text for more details."}
##  out.width = "100%",
tree<-read.tree(text="(C:0.7,(B:0.3,A:0.3):0.4);")
x<-setNames(c(0,0,1),LETTERS[3:1])
tt<-bind.tip(tree,"internal",edge.length=0,where=5)
plotTree(tree,ftype="i",offset=1,fsize=1.2,ylim=c(1,3.2))
pp<-get("last_plot.phylo",envir=.PlotPhyloEnv)
points(pp$xx[4:5],pp$yy[4:5],pch=21,cex=2,bg="white")
points(pp$xx[4:5],pp$yy[4:5],pch=16,cex=1.2,col="black")
text(pp$xx[4]+0.05,pp$yy[4]-0.05,"root",font=3)
text(pp$xx[5],pp$yy[5]-0.15,"internal",font=3,pos=2)
points(rep(0.7,3),1:3,pch=22,cex=2.5,bg=c("white","white","black"))
text(0.35,1.1,expression(paste('t'[C]," = 0.7")),cex=0.8)
text(0.2,2.6,expression(paste('t'[AB]," = 0.4")),cex=0.8)
text(0.55,2.1,expression(paste('t'[B]," = 0.3")),cex=0.8)
text(0.55,3.1,expression(paste('t'[A]," = 0.3")),cex=0.8)
legend("topleft",legend=0:1,pch=22,pt.bg=c("white","black"),
  pt.cex=2.5,bty="n",horiz=TRUE,inset=0.02)
```

Figure 1 shows a simplified rooted phylogeny with three terminal taxa (*A*, *B*, and *C*) and two observed levels (0 and 1) of a discrete phenotypic trait. To compute the probability of the observed data at the tips of this tree under our Markov chain (M*k*) model, we might begin by calculating $\mathbf{P}_{t=0.4}$, $\mathbf{P}_{t=0.3}$, and $\mathbf{P}_{t=0.7}$ for our transition matrix **Q**. If we were to do so, we'd obtain the following three values.\footnote{Our tree has a total of four edges, but two of them have exactly the same total length of $t = 0.3$ (Figure 1).}

```{r, echo=FALSE, results="hide", message=FALSE}
Q<-matrix(c(-0.2,0.2,0.2,-0.2),2,2,
  dimnames=list(0:1,0:1))
expm(Q*0.4)->P4
P4
```
```{r, echo=FALSE, results="hide", message=FALSE}
expm(Q*0.7)->P7
P7
```
```{r, echo=FALSE, results="hide", message=FALSE}
expm(Q*0.3)->P3
P3
```

$$\mathbf{P}_{t=0.4} = \exp({\mathbf{Q} \times 0.4}) = \begin{bmatrix}0.926 & 0.074\\0.074 & 0.926\end{bmatrix}$$

$$\mathbf{P}_{t=0.3} = \exp({\mathbf{Q} \times 0.3}) = \begin{bmatrix}0.943 & 0.057\\0.057 & 0.943\end{bmatrix}$$

$$\mathbf{P}_{t=0.7} = \exp({\mathbf{Q} \times 0.7}) = \begin{bmatrix}0.878 & 0.122\\0.122 & 0.878\end{bmatrix}$$

Now, with these probability matrices in hand, we can proceed on to measuring the total probability of the data at the tips of the tree of Figure 1. To do this, one more probability that we need to consider is the (prior) probability that the global root of the tree was in condition 0 or condition 1 -- normally given as $\pi_{0}$ and $\pi_{1}$, respectively. There are various ways we might set $\pi$ [see @FitzJohn2009; @Yang2014-book; @Revell2022-book]. For simplicity here, I'll just say $\pi_{0} = \pi_{1} = 0.5$ (a 'flat' root prior); however, identifying a suitable root prior ($\mathbf{\pi}$) has been the subject of more substantive discussion elsewhere [@FitzJohn2009; @Yang2014-book]. 

Having set $\mathbf{\pi}$, we can compute the total probability of our data by summing the probability of our tip data (*A* in condition 1, *B* in 0, and *C* in 0, shown here as $P(1,0,0)$), across all four possible combinations of states at the root and internal nodes of our tree, respectively: 0 & 0, 0 & 1, 1 & 0, and 1 & 1.

```{r, echo=FALSE, results="hide", message=FALSE}
P=0.5*P4[1,1]*P3[1,2]*P3[1,1]*P7[1,1]+
  0.5*P4[1,2]*P3[2,2]*P3[2,1]*P7[1,1]+
  0.5*P4[2,1]*P3[1,2]*P3[1,1]*P7[2,1]+
  0.5*P4[2,2]*P3[2,2]*P3[2,1]*P7[2,1]
P
```

$$\begin{aligned}
P(1,0,0) &= \pi_{0} \times P(0|0,t_{AB}) \times P(1|0,t_{A}) \times P(0|0,t_{B}) \times P(0|0,t_{C})\\ 
            & + \pi_{0} \times P(1|0,t_{AB}) \times P(1|1,t_{A}) \times P(0|1,t_{B}) \times P(0|0,t_{C})\\
            & + \pi_{1} \times P(0|1,t_{AB}) \times P(1|0,t_{A}) \times P(0|0,t_{B}) \times P(0|0,t_{C})\\
            & + \pi_{1} \times P(1|1,t_{AB}) \times P(1|1,t_{A}) \times P(0|1,t_{B}) \times P(0|1,t_{C})\\
            & = 0.0267
\end{aligned}$$

In which $P(1|0,t_{A})$ is the (1,2)th element of $\mathbf{P}_{t=0.3}$, $P(0|0,t_{C})$ is the (2,2)th element of $\mathbf{P}_{t=0.7}$, and so on [@Yang2014-book; @Harmon2019-book].

After we calculate all the relevant quantities of our equation, we should find that the total probability of our data on this tree is 0.0267, given our transition matrix (**Q**) and modeled process.\footnote{Importantly, this is the probability of observing the data pattern [1, 0, 0] given our tree and matrix \textbf{Q}, not the probability of the tree or \textbf{Q}. That means that if we were to identify all possible data patterns ([0, 0, 0], [0, 0, 1], and so on), compute their probabilities, and then sum these quantities, this sum should be equal to 1.0.} In this case, for demonstrative purposes only, I've explicitly enumerated all of the possible internal node and root states of our tree; however, this would become very onerous for even a modestly-sized phylogeny of five or ten operational taxa.\footnote{Indeed, it's virtually impossible for larger trees.} Fortunately, @Felsenstein1981 described a highly efficient 'pruning'\footnote{Felsenstein's procedure is called a pruning algorithm because it proceeds in a ``post-order'' fashion -- that is, from the tips towards the root of the tree -- performing a calculation based only on the descendant subtree of each internal node, pruning this subtree out of the phylogeny, and then using the computed quantities for the next, more rootward calculation.} algorithm to compute this exact probability.

So far we've treated **Q** as if it were fixed. In practice, we invariably *estimate* **Q**, typically by identifying the value of **Q** that maximizes the probability of our data given the tree: our Maximum Likelihood estimate, by definition [@Revell2022-book]. Obviously, it makes little sense to try and estimate **Q** from a tree containing only three observations! Consequently, for now we'll continue using this same fixed value of **Q**, but we should at the same time keep in mind that in any empirical studies **Q** is nearly invariably estimated from the same data that are being used to reconstruct ancestral states -- rather than set to a fixed value or known \emph{a priori}.

## Marginal vs. joint ancestral state estimation

An important consideration when discussing ancestral state reconstruction of discrete characters is the distinction between what are known as *marginal* and *joint* reconstruction [@Yang2006-book; @Revell2022-book].\footnote{In theory, the same distinction could be made for continuous traits -- except that, in that case, our marginal and joint estimates are the same!} Marginal reconstruction involves proceeding from node to node on the phylogeny, and, at each node, computing the probability of observing the tip data of our tree conditioned on fixing the node we've visited to each one of the set of distinct values of our trait. This set of probabilities, referred to as marginal likelihoods, are normally rescaled such that they add to 1.0,\footnote{Doing so merely entails dividing each by the total likelihood.} at which point they're frequently referred to as the node *marginal scaled likelihoods*. Yang [-@Yang2006-book; -@Yang2014-book] has pointed out that these scaled likelihoods are also a type of empirical Bayes posterior probability.\footnote{Empirical Bayes estimation involve fixing one level of the Bayesian heirarchy -- in this case, the value of our transition matrix \textbf{Q} -- to its most likely value, and then computing our posterior probabilities conditioning on this fixed level.} They can thus be validly interpreted as the (posterior) probabilities that each node is in each of the observed character states, whilst conditioning on our fitted transition process, **Q**. Joint reconstruction, on the other hand, involves identifying the set of all internal node values (among all possible such sets) that maximizes the probability of our data. As observed by @Yang2006-book, these needn't necessarily be the set of states with the highest marginal scaled likelihoods!

## Marginal ancestral state estimation

Marginal ancestral state reconstruction involves traversing the tree and at each node calculating the probability of the tip data in our tree under our model, conditioned on our current node being in each of our character levels. These 'marginal' probabilities are then normalized by dividing by their sum at each node, at which point they can be interpreted as the (empirical Bayes posterior) probability that each node is in each state of the character [@Yang2006-book; @Revell2022-book]. Since we've already calculated all the relevant quantities for our example of Figure 1, let's proceed and evaluate first the marginal likelihoods at the root, then the marginal likelihoods for our single internal node.

```{r, echo=FALSE, results="hide", message=FALSE}
P0=0.5*P4[1,1]*P3[1,2]*P3[1,1]*P7[1,1]+
  0.5*P4[1,2]*P3[2,2]*P3[2,1]*P7[1,1]
P0
```
```{r, echo=FALSE, results="hide", message=FALSE}
P1=0.5*P4[2,1]*P3[1,2]*P3[1,1]*P7[2,1]+
  0.5*P4[2,2]*P3[2,2]*P3[2,1]*P7[2,1]
P1
```
$$\begin{aligned}
P(root=0) & = \pi_{0} \times P(0|0,t_{AB}) \times P(1|0,t_{A}) \times P(0|0,t_{B}) \times P(0|0,t_{C})\\ 
            & + \pi_{0} \times P(1|0,t_{AB}) \times P(1|1,t_{A}) \times P(0|1,t_{B}) \times P(0|0,t_{C})\\
            & = 0.5 \times 0.0434 + 0.5 \times 0.0035\\
            & = 0.0234
\end{aligned}$$

$$\begin{aligned}
P(root=1) & = \pi_{1} \times P(0|1,t_{AB}) \times P(1|0,t_{A}) \times P(0|0,t_{B}) \times P(0|1,t_{C})\\
            & + \pi_{1} \times P(1|1,t_{AB}) \times P(1|1,t_{A}) \times P(0|1,t_{B}) \times P(0|1,t_{C})\\
            & = 0.5 \times 0.0005 + 0.5 \times 0.0060 \\
            & = 0.0033
\end{aligned}$$

```{r, echo=FALSE, results="hide", message=FALSE}
c(P0,P1)/(P0+P1)
```
Here $P(root = 0)$ gives the probability of our observed data (conditioning on **Q**), given that the root is in state 0; while $P(root = 1)$ gives the probability of our data, given that the root is in state 1.\footnote{Importantly, $P(root = 0)$ and $P(root = 1)$ \emph{do not} give the probability that the root state was in condition 0 or condition 1, respectively. If they did, then we would expect their values to add to 1.0!} If these two quantities are rescaled by their sum, however (which is also, recall, the total likelihood), we obtain the marginal scaled likelihoods for states 0 and 1 of $P(0,1) = [0.878, 0.122]$ at the root node of the tree.

Now let's repeat the same procedure for the single internal node of our phylogeny of Figure 1.

```{r, echo=FALSE, results="hide", message=FALSE}
P0=0.5*P4[1,1]*P3[1,2]*P3[1,1]*P7[1,1]+
  0.5*P4[2,1]*P3[1,2]*P3[1,1]*P7[2,1]
P0
```
```{r, echo=FALSE, results="hide", message=FALSE}
P1=0.5*P4[1,2]*P3[2,2]*P3[2,1]*P7[1,1]+
  0.5*P4[2,2]*P3[2,2]*P3[2,1]*P7[2,1]
P1
```
$$\begin{aligned}
P(internal=0) & = \pi_{0} \times P(0|0,t_{AB}) \times P(1|0,t_{A}) \times P(0|0,t_{B}) \times P(0|0,t_{C})\\ 
            & + \pi_{1} \times P(0|1,t_{AB}) \times P(1|0,t_{A}) \times P(0|0,t_{B}) \times P(0|1,t_{C})\\
            & = 0.5 \times 0.0434 + 0.5 \times 0.0005 \\
            & = 0.0219
\end{aligned}$$

$$\begin{aligned}
P(internal=1) & = \pi_{0} \times P(1|0,t_{AB}) \times P(1|1,t_{A}) \times P(0|1,t_{B}) \times P(0|0,t_{C})\\
            & + \pi_{1} \times P(1|1,t_{AB}) \times P(1|1,t_{A}) \times P(0|1,t_{B}) \times P(0|1,t_{C})\\
            & =  0.5 \times 0.0035 + 0.5 \times 0.0060 \\
            & = 0.0047
\end{aligned}$$

```{r, echo=FALSE, results="hide", message=FALSE}
c(P0,P1)/(P0+P1)
```
Once again, if these two quantities are rescaled by their sum, which is also the total likelihood (just as it was for the root node), we'll have the marginal scaled likelihoods for conditions 0 and 1 of $P(0,1) = [0.822, 0.178]$. Figure 2a gives the marginal ancestral state reconstruction of our tree and data in Figure 1,\footnote{Mapped to the corresponding nodes of the tree using a pie diagram, as is very commonly done in empirical studies that use marginal ancestral state reconstruction.} conditioned on the value of **Q** indicated earlier in the chapter.

```{r fig2, echo=FALSE, fig.width=5, fig.height=2.5, dpi=300, fig.cap="(a) Marginal ancestral state reconstruction based on the tree and data of Figure 1. (b) Joint ancestral reconstruction. See main text for more details."}
par(mfrow=c(1,2))
plotTree(tree,ftype="i",offset=1,fsize=1.2,mar=c(0.1,1.1,2.1,1.1),
  xlim=c(-0.1,0.9),ylim=c(0.7,3.3))
points(rep(0.7,3),1:3,pch=22,cex=2.5,bg=c("white","white","black"))
anc<-ancr(fitMk(tree,x,fixedQ=Q))
nodelabels(pie=anc$ace,piecol=c("white","black"),cex=2)
mtext("a) marginal reconstruction",adj=0.1,line=1)
plotTree(tree,ftype="i",offset=1,fsize=1.2,mar=c(0.1,1.1,2.1,1.1),
  xlim=c(-0.1,0.9),ylim=c(0.7,3.3))
points(rep(0.7,3),1:3,pch=22,cex=2.5,bg=c("white","white","black"))
nodelabels(pie=matrix(c(1,1,0,0)),piecol=c("white","black"),cex=2)
mtext("b) joint reconstruction",adj=0.1,line=1)
```

## Joint reconstruction

The other type of ancestral state reconstruction that we might perform under the M*k* model, in addition to the method of marginal ancestral state reconstruction that we just learned, is what's typically referred to as *joint* reconstruction [@Yang2006-book; @Revell2022-book]. In this case, our estimated ancestral states are merely the set of such states that jointly maximize the probability of our data at the tips of the tree.

In our example from Figure 1, there are a total of four possible *sets* of states at the two nodes of the phylogeny: $[0,0]$, $[0,1]$, $[1,0]$, and $[1,1]$.\footnote{In general, there will be a number $k^m$ of such sets for $k$ character levels and $m$ nodes.} Uncoincidentally, these four sets of states correspond to the four terms of our equation for the probability of our data ($P(0,0,1)$), above. In other words:

```{r, echo=FALSE, results="hide", message=FALSE}
P00=0.5*P4[1,1]*P3[1,2]*P3[1,1]*P7[1,1]
P00
```
```{r, echo=FALSE, results="hide", message=FALSE}
P01=0.5*P4[1,2]*P3[2,2]*P3[2,1]*P7[1,1]
P01
```
```{r, echo=FALSE, results="hide", message=FALSE}
P10=0.5*P4[2,1]*P3[1,2]*P3[1,1]*P7[2,1]
P10
```
```{r, echo=FALSE, results="hide", message=FALSE}
P11=0.5*P4[2,2]*P3[2,2]*P3[2,1]*P7[2,1]
P11
```
$$\begin{aligned}
P([0,0]) & = \pi_{0} \times P(0|0,t_{AB}) \times P(1|0,t_{A}) \times P(0|0,t_{B}) \times P(0|0,t_{C}) = 0.0217\\ 
P([0,1]) & = \pi_{0} \times P(1|0,t_{AB}) \times P(1|1,t_{A}) \times P(0|1,t_{B}) \times P(0|0,t_{C}) = 0.0017\\
P([1,0]) & = \pi_{1} \times P(0|1,t_{AB}) \times P(1|0,t_{A}) \times P(0|0,t_{B}) \times P(0|1,t_{C}) = 0.0002\\
P([1,1]) & = \pi_{1} \times P(1|1,t_{AB}) \times P(1|1,t_{A}) \times P(0|1,t_{B}) \times P(0|1,t_{C}) = 0.0030\\
\end{aligned}$$

Here, $P([0,0])$ gives the probability of our data at the tips of the tree, conditioning on both the root and single internal node of the tree being in states 0 and 0, respectively. The same interpretation can be made of $P([0,1])$, $P([1,0])$, and so on. From this set of values we can see that the combination of states that jointly maximizes the probability of our data are $[0,0]$ -- in other words, condition 0 at both the root and single internal node of the tree (Figure 1). This set thus becomes our *joint* Maximum Likelihood ancestral state estimate. We could also imagine rescaling the set of probability values by their sum and reporting the probabilities of each set of states conditioned on **Q** -- though this is not typically undertaken in joint reconstruction. Figure 2b illustrates the joint reconstruction from our tree and data of Figure 1.

## Stochastic character mapping

In addition to joint and marginal reconstruction, a third important and popular method of ancestral state estimation under the M*k* model is the procedure called stochastic character mapping [@Huelsenbeck2003; @Bollback2006; @Revell2022-book; @Revell2024].\footnote{Stochastic character mapping originally derives from a closely related approach called `mutational mapping' (Nielsen 2002) and was first generalized to phenotypic traits by Huelsenbeck et al. (2003).} Under stochastic character mapping, complete character histories (including character state changes along the branches of the tree) are randomly\footnote{In other words, ``stochastically,'' hence the name of the method.} sampled from their probability distribution under a model. 

Stochastic character mapping is a computationally intensive method. The most efficient algorithm to generate a single stochastic character map minimally involves two traversals of the tree. The first of these is a post-order (tip to root) "pruning" traversal in which a set of conditional likelihoods of each subtree is calculated for each node of the tree. These are the set of marginal likelihoods, under our model, for *only* the data descended from a given node.\footnote{Note that if we generate more than one stochastically mapped history for a given tree and value of \textbf{Q}, as we nearly invariably should, these values can be recycled across simulations and do not need to be recomputed.} Once the root node is reached, these calculated quantities *also* correspond to the marginal likelihoods at this node and sum to the total probability of our data under the model. A root state is randomly sampled with probability equal to its marginal scaled likelihoods. 

Next, we undertake a pre-order tree traversal. Looking at each daughter node from the root, we first calculate a set of updated probablities (**p**) that each of the two or more daughters is in each state of our character. For each daughter, this vector of probabilities, **p**, is simply equal to the *i*th row of the exponentiated product of **Q**, the transition matrix, and the elapsed time of the daughter edge, multiplied element-wise\footnote{Also known as the Hadamard product.} by the vector of conditional likelihoods of the subtree for that node -- the values that we computed in our prior post-order tree traversal. In other words, $\mathbf{p} = \exp(\mathbf{Q}t)_{i\cdot} \odot \mathbf{L}$, in which the subscript $i\cdot$ indicates the *i*th row of $\exp(\mathbf{Q}t)$, $\odot$ is the element-wise vector product, and **L** is a vector of conditional likelihoods. 

We then proceed to the daughter node and randomly sample a state for it according to the probabilities given by **p**. We use simulation and rejection sampling to obtain a discrete character character history along that edge consistent with our sampled parent and daughter node states. Finally, we recursively traverse the phylogeny in a post-order (root to tip) fashion repeating this procedure for each pair of parent and daughter nodes.\footnote{Of course, if the daughter node is a tip then typically the state will be known rather than sampled probabilistically, but our procedure is otherwise identical.} Figure 3 gives an example of ten stochastic character histories, given our phylogeny and data of Figure 1 and the **Q** transition matrix of our previous sections in which $q_{0,1} = q_{1,0} = 0.2$. Normally, we'd generate many more than ten stochastic character histories!

```{r fig3, echo=FALSE, fig.width=5, fig.height=3, dpi=300, fig.cap="A set of ten stochastic character maps for the tree and data of Figure 1. See main text for more details."}
mat<-matrix(c(1:10,rep(11,5)),3,5,byrow=TRUE)
set.seed(17)
smap<-make.simmap(tree,x,Q=Q,nsim=10,message=FALSE)
layout(mat,heights=c(0.45,0.45,0.1))
cols<-setNames(c("white","black"),0:1)
plot(smap,cols,ftype="i",lwd=5,outline=TRUE,ylim=c(0.7,3.3))
par(mar=rep(0,4))
plot(NA,xlim=c(0,1),ylim=c(0,1),bty="n",axes=FALSE,
  xlab="",ylab="")
legend("center",legend=0:1,pch=22,pt.bg=c("white","black"),
  horiz=TRUE,bty="n",cex=1.5,pt.cex=2)
```

A single stochastic character map contains almost no information about evolutionary history, but a set of many such maps can be used to measure the posterior probabilities that each node is in each state of our character, as well as to generate an estimate of the probability distribution of the number of changes of each type on the tree. Indeed, when a single, fixed value of **Q** is used for stochastic mapping, the relative frequencies of each state at each node and the marginal scaled likelihoods from our previous section should exactly converge as the number of stochastic simulations goes to $\infty$.\footnote{Though normally they will be highly similar after 100 or 1,000 simulations.} An advantage of stochastic character mapping, however, is that it also allows us to take into account uncertainty in the transition process represented by **Q**. For example, it's straightforward to sample **Q** from its Bayesian posterior distribution using MCMC, or to use a set of transition processes in proportion to their weight based on model comparison [e.g., @Revell2022-book; @Revell2024].

## Empirical examples 

### Marginal reconstruction: Diel activity pattern in primates

To demonstrate marginal reconstruction, we'll study diel activity pattern\footnote{Coded as `nocturnal,' `diurnal,' and `cathemeral' (active randomly during the day or night) in these data.} among 90 species of primates. The phylogeny and data for this example come from Kirk and Kay [-@Kirk2004; but see a similar analysis using different data in @Santini2015].

Our first step, in this case, will be to fit a set of four M*k* models to our tree and data. We can begin with a very simple model in which we assume that the rates of transitions between all three pairs of our states (nocturnal $\leftrightarrow$ diurnal, nocturnal $\leftrightarrow$ cathemeral, and diurnal $\leftrightarrow$ cathemeral) are all equal one to the other, and in both directions. This model is called the 'equal-rates' (ER) model and our matrix, **Q**, will have just one parameter to be estimated. Next, we might proceed to fit a model in which the backward and forward transition rates between each pair of states are equal (one to the other), but different for each character state pair. This is called the 'symmetric' (SYM) model and has a total of three parameters. We'll fit a model in which every transition rate in each direction is permitted to assume a different rate. This is called the 'all-rates-different' (ARD) model, and our **Q** matrix for this model will include a total of six parameters to be estimated.\footnote{In general the ARD model has a total of $k \times (k-1)$ parameters for $k$ states.} Lastly, we'll fit a model in which we imagine that the cathemeral condition is intermediate between the nocturnal and diurnal activity states, whereby any lineage evolving from one to the other must first pass through the state of cathemeral diel activity. This set of fitted models, and their AIC values and Akaike weights, is given in Figure 4.

```{r, echo=FALSE, results="hide", message=FALSE}
data(primate.tree)
data(primate.data)
activity<-setNames(primate.data$Activity_pattern,
  rownames(primate.data))
```
```{r, echo=FALSE, results="hide", message=FALSE, eval=FALSE}
er_model<-fitMk(primate.tree,activity,model="ER")
sym_model<-fitMk(primate.tree,activity,model="SYM")
ard_model<-fitMk(primate.tree,activity,model="ARD")
MODEL<-matrix(c(
  0,1,2,
  3,0,0,
  4,0,0),3,3,byrow=TRUE,
  dimnames=list(levels(activity),levels(activity)))
ordered_model<-fitMk(primate.tree,activity,model=MODEL)
save(er_model,sym_model,ard_model,ordered_model,file="data/primates.rda")
```
```{r, echo=FALSE, results="hide", message=FALSE}
load("data/primates.rda")
primate.aov<-anova(er_model,sym_model,ordered_model,ard_model)
```
```{r fig4, echo=FALSE, fig.width=9, fig.height=6, dpi=300, out.width = "100%", fig.cap="A set of fitted M\\emph{k} models for the evolution of diel activity pattern in primates. (a) The equal-rates (ER) model. (b) The symmetric (SYM) model. (c) An ordered model in which the cathemeral state is assumed to be intermediate between the other two conditions. Finally, (d) the all-rates-different (ARD) model. Note that the legend color gradient differs for each figure panel. Model-support and Akaike weights are indicated in each panel header. See main text for more details."}
par(mfrow=c(2,2),mar=c(0.1,0.1,0.1,0.1))
plot(er_model,color=TRUE,width=TRUE,spacer=0.4,offset=0.04,
  palette="black",xlim=c(-1.8,1),ylim=c(-1,1))
mtext(paste("a) AIC = ",round(primate.aov$AIC[1],2),"; model weight = ",
  round(primate.aov$weight[1],2),sep=""),line=1,adj=0.1)
plot(sym_model,color=TRUE,width=TRUE,spacer=0.4,offset=0.04,
  palette=c("lightgrey","black"),xlim=c(-1.8,1),ylim=c(-1,1))
mtext(paste("b) AIC = ",round(primate.aov$AIC[2],2),"; model weight = ",
  round(primate.aov$weight[2],2),sep=""),line=1,adj=0.1)
plot(ordered_model,color=TRUE,width=TRUE,spacer=0.4,offset=0.04,
  palette=c("lightgrey","black"),xlim=c(-1.8,1),ylim=c(-1,1),
  show.zeros=FALSE)
mtext(paste("c) AIC = ",round(primate.aov$AIC[3],2),"; model weight = ",
  round(primate.aov$weight[3],2),sep=""),line=1,adj=0.1)
plot(ard_model,color=TRUE,width=TRUE,spacer=0.4,offset=0.04,
  palette=c("lightgrey","black"),xlim=c(-1.8,1),ylim=c(-1,1))
mtext(paste("d) AIC = ",round(primate.aov$AIC[4],2),"; model weight = ",
  round(primate.aov$weight[4],2),sep=""),line=1,adj=0.1)
```

Since the weight of evidence is fairly even across each in our set of four models\footnote{This is a bit unusual, in my experience. Typically, one model tends to be substantially better-supported than the rest!}, I elected to use model-averaged marginal ancestral state estimation.\footnote{Model-averaging simply involves taking the Akaike weights, multiplying them by the marginal scaled likelihoods for each model, and then summing across models (Revell, 2024).} The resultant marginal ancestral states are shown in Figure 5. They reveal that the common ancestor was most likely nocturnal (under our fitted model), and also suggest multiple transitions to diurnal diel activity pattern in different parts of the primate tree of life (Figure 5).

```{r fig5, echo=FALSE, fig.width=8, fig.height=3.5, dpi=300, out.width = "100%", fig.cap="Model-averaged marginal ancestral state reconstruction of diel activity pattern in primates, integrating over the four models of Figure 4 in proportion to their Akaike weights. Nodes in which no single condition had a model-averaged marginal scaled likelihood > 0.95 are shown in larger size. See main text for more details."}
primate.anc<-ancr(primate.aov)
cols<-setNames(grey(c(0.4,0.9,0)),levels(activity))
pie_cex<-apply(primate.anc$ace,1,function(x) if(any(x>=0.95)) 0.3 else 0.6)
plot(primate.anc,args.nodelabels=list(piecol=cols,cex=pie_cex),
  direction="upwards")
```

### Joint reconstruction: Tail spines in lizards

To illustrate joint reconstruction, we'll use a phylogeny from @Pyron2013 along with a dataset of tail spine presence and absence in lizards originally published by @Ramm2020. To commence, we can fit a set of just two M*k* models for this binary trait: the ER model, in which the back-and-forth transitions between our two states are forced to take place at the same rate; and the ARD model in which they can differ.\footnote{We might have also considered two irreversible models: one in which tail spines can \emph{only} be gained in our tree; and another in which they are only lost. In this case, doing so would not have substantively changed our results.}

```{r, echo=FALSE, results="hide", message=FALSE}
lizard_tree<-read.nexus(file="http://www.phytools.org/Rbook/7/lizard_tree.nex")
lizard_data<-read.csv(file="http://www.phytools.org/Rbook/7/lizard_spines.csv",
  row.names=1,stringsAsFactors=TRUE)
chk<-geiger::name.check(lizard_tree,lizard_data)
lizard_tree<-drop.tip(lizard_tree,chk$tree_not_data)
tail_spines<-setNames(lizard_data$tail.spines,rownames(lizard_data))
```
```{r, echo=FALSE, results="hide", message=FALSE, eval=FALSE}
er_model<-fitMk(lizard_tree,tail_spines,model="ER")
ard_model<-fitMk(lizard_tree,tail_spines,model="ARD")
save(er_model,ard_model,file="data/lizards.rda")
```
```{r, echo=FALSE, results="hide", message=FALSE}
load("data/lizards.rda")
lizard.aov<-anova(er_model,ard_model)
lizard.aov<-cbind(data.frame(
  q01=c(er_model$rates,ard_model$rates[2]),
  q10=c(er_model$rates,ard_model$rates[1])),
  lizard.aov)
```
```{r, echo=FALSE, results='asis'}
options(knitr.kable.NA = '--')
colnames(lizard.aov)<-c(
  "$q_{0,1}$","$q_{1,0}$",
  "log(L)","d.f.","AIC","weight")
rownames(lizard.aov)<-c("ER model","ARD model")
knitr::kable(lizard.aov,digits=5,escape=FALSE,caption="Estimated transition rates, log-likelihood, number of parameters, AIC, and model weights for two different discrete character evolution models for the evolution of the presence or absence of tail spines in lizards. See main text for more details.")
```
The results from this analysis are shown in Table 1. Our analysis indicates much higher model weight (0.93 vs. 0.07) for the ARD compared to the ER model. Consequently, we used only this model for our subsequent joint ancestral state reconstruction, given in Figure 6.\footnote{An interesting `footnote' (get it?) to this result is that the ML joint reconstruction at the global root of the tree is `non-spiny,' but in an analogous marginal reconstruction the most \emph{probable} condition for the same node was `spiny.' We haven't included this analysis here, but the reader is encouraged to download the data and discover this for themselves!}

```{r, echo=FALSE, results="hide", message=FALSE, eval=FALSE}
lizard.anc<-ancr(ard_model,type="joint")
save(er_model,ard_model,lizard.anc,file="data/lizards.rda")
```
```{r fig6, echo=FALSE, fig.width=9.5, fig.height=5.5, dpi=300, out.width = "100%", fig.cap="Joint reconstruction of the presence and absence of tail spines on a phylogeny of 658 species of lizards. Reconstruction was performed under the best-supported M\\emph{k} model which featured unequal back and forth transition rates between the two different character levels of the tree (the ARD model; Table 1). See main text for more details."}
load("data/lizards.rda")
cols<-setNames(grey(c(0.8,0)),levels(tail_spines))
plot(lizard.anc,type="arc",arc_height=0.25,ylim=c(-20,220),
  args.nodelabels=list(piecol=cols,cex=0.2))
```

Joint reconstruction involves a key difference in interpretation compared to marginal reconstruction. Now, we can no longer point to a particular node and say that the most probable state is "spiny" or "non-spiny." Rather, we might say that "in the most probable joint reconstruction, the ancestral condition at the global root was non-spiny," or something to that effect. Since researchers more often wish to be able to make specific statements about particular nodes,\footnote{Rather than the most probable set of conditions across \emph{all} nodes.} marginal reconstruction tends to be the much more popular of these two techniques among comparative biologists.

### Stochastic character mapping: Leaf armature in palms

```{r, echo=FALSE, results="hide", message=FALSE}
palm_tree<-read.tree(file="data/Onstein_etal.tre")
palm_data<-read.csv(file="data/trait_data_Onstein_et_al.csv",
  row.names=1)
chk<-geiger::name.check(palm_tree,palm_data)
leaf_armature<-matrix(0.5,Ntip(palm_tree),2,
  dimnames=list(palm_tree$tip.label,c("absent","present")))
for(i in 1:nrow(leaf_armature)){
  ii<-which(rownames(palm_data)==rownames(leaf_armature)[i])
  if(length(ii)==1){ 
    leaf_armature[i,]<-
      if(is.na(palm_data[ii,"armature_leaf"])) c(0.5,0.5) else
      if(palm_data[ii,"armature_leaf"]==1) c(0,1) else
      if(palm_data[ii,"armature_leaf"]==0) c(1,0)
  }
}
```
```{r, echo=FALSE, results="hide", message=FALSE, eval=FALSE}
er_model<-fitMk(palm_tree,leaf_armature,model="ER",
  rand_start=TRUE)
irr1_model<-fitMk(palm_tree,leaf_armature,
  model=matrix(c(0,1,0,0),2,2,byrow=TRUE),
  rand_start=TRUE)
irr2_model<-fitMk(palm_tree,leaf_armature,
  model=matrix(c(0,0,1,0),2,2,byrow=TRUE),
  rand_start=TRUE)
ard_model<-fitMk(palm_tree,leaf_armature,model="ARD",
  rand_start=TRUE)
save(er_model,irr1_model,irr2_model,ard_model,file="data/palms.rda")
```
```{r, echo=FALSE, results="hide", message=FALSE}
load("data/palms.rda")
palm.aov<-anova(er_model,irr1_model,irr2_model,ard_model)
```
```{r, echo=FALSE, results="hide", message=FALSE, eval=FALSE}
palm_smap<-simmap(palm.aov,nsim=500)
save(er_model,irr1_model,irr2_model,ard_model,palm_smap,
  file="data/palms.rda")
```

To demonstrate stochastic character mapping, I used a recent dataset and phylogeny published by @Onstein2022. In this example, the phylogeny contains a total of 2,539 tree species from the family Arecaceae (the palms), and data for the presence of absence of leaf armature (spines, hooks, or prickles on the palm leaves) for all but 120 of these taxa. The trait data of this study were compiled by @Onstein2022 from the PalmTraits 1.0 database [@Kissling2019], and the palm phylogeny is derived from an earlier tree by @Faurby2016.

To begin, I re-coded all data deficient species [which had been left out by @Onstein2022] as ambiguous\footnote{Coding for ambiguity simply involves observing, \emph{a priori}, that an ambiguous tip could equally likely be in one condition or the other. The total probability of the data then becomes the sum of the probability conditioning first on the tip state being in one state and then in the other. This total probability can be computed efficiently via the pruning algorithm of Felsenstein (1981).} for the trait of leaf armature, and then I proceeded to fit a total of four M*k* trait evolution models: the ER model, the ARD model, and two irreversible models (one in which leaf armature could be acquired but not lost, and a second in which the reverse was true). A summary of parameter estimates and model support is given in Table 2. I found almost no support for the two irreversible models, but roughly similar weights of evidence for the two different reversible models: ER and ARD (Table 2).

```{r, echo=FALSE, results='asis'}
palm.aov<-cbind(data.frame(
  q01=c(er_model$rates,irr1_model$rates,0,ard_model$rates[2]),
  q10=c(er_model$rates,0,irr2_model$rates,ard_model$rates[1])),
  palm.aov)
options(knitr.kable.NA = '--')
colnames(palm.aov)<-c(
  "$q_{0,1}$","$q_{1,0}$",
  "log(L)","d.f.","AIC","weight")
rownames(palm.aov)<-c("ER model","absent $\\rightarrow$ present",
  "present $\\rightarrow$ absent","ARD model")
knitr::kable(palm.aov,digits=5,escape=FALSE,caption="Estimated transition rates, log-likelihood, number of parameters, AIC, and model weights for four different discrete character evolution models for the evolution of the presence or absence of leaf armature in palms. See main text for more details.")
```

I next generated 500 stochastic character maps in which each of the four models were sampled randomly with probabilities given by their relative model weights (Table 2). Note that the sampling algorithm and total sample size of stochastic character maps is such that it ensures almost no irreversible (absent $\rightarrow$ present or present $\rightarrow$ absent) stochastic character histories will be sampled. A single, randomly chosen stochastic mapped tree is shown in Figure 7.

```{r fig7, echo=FALSE, fig.width=9, fig.height=4.75, dpi=300, out.width = "100%", fig.cap="A single stochastically-sampled character history of the absence (grey) or presence (black) of leaf armature (spines or other defensive structures) in 2,539 species of palms. The phylogeny and data for this example come from Faurby et al. (2016) and Onstein et al. (2022), respectively. See main text for more details."}
load(file="data/palms.rda")
cols<-setNames(c(grey(0.8),"black"),c("absent","present"))
plot(sample(palm_smap,1)[[1]],cols,type="arc",arc_height=0.5,ftype="off",lwd=1)
par(lend=2)
legend("topleft",names(cols),title="leaf armature",lwd=4,col=cols,bty="n")
```

Normally, relatively little can be learned from a single, stochastic character history such as that shown in Figure 7. On the other hand, neither is anything to be gained by visualizing 500 such histories -- particularly for large phylogenetic trees! For this reason, various tactics have been proposed to summarize the results across a set of stochastic character maps [@Revell2013; @Revell2014; @Revell2022-book; @Revell2024]. Two such analyses are shown in Figure 8. In particular, Figure 8a shows a posterior density map [@Revell2013; @Revell2014] obtained by measuring the relative frequency of each of the two states over our set of 500 stochastic simulations across all edges and nodes of the tree. These frequencies give the posterior probabilities\footnote{These will be empirical Bayes posterior probabilities for a fixed value of \textbf{Q}; however, full Bayesian probabilities are also possible -- for example, if the \textbf{Q} matrix is sampled from its posterior probability distribution using MCMC.} along all of the edges and nodes of the phylogeny. Figure 8b, on the other hand, illustrates a visualization of the posterior probability distribution of the number of changes of each type on the phylogeny. These distributions are obtained simply by counting the changes in each of the 500 stochastically sampled character maps [e.g., @Revell2024].

```{r, echo=FALSE, results="hide", message=FALSE, eval=FALSE}
load(file="data/palms.rda")
palm_dmap<-densityMap(palm_smap,plot=FALSE,res=200)
palm_dmap<-setMap(palm_dmap,c(grey(0.8),"black"))
save(er_model,irr1_model,irr2_model,ard_model,palm_smap,palm_dmap,
  file="data/palms.rda")
```
```{r fig8, echo=FALSE, fig.width=9, fig.height=9.5, dpi=300, out.width = "100%", fig.cap="(a) Probability density of the absence/presence of leaf armature based on 500 stochastic character mapping on a phylogenetic tree of 2,539 palm species. The four models of Table 2 were randomly sampled in proportion to their model weights following Revell (2024). Probability density of changes from leaf armature absent to present (b) and present to absent (c) from 500 stochastic character maps."}
load(file="data/palms.rda")
mat<-matrix(c(1,1,2,3),2,2,byrow=TRUE)
layout(mat)
plot(palm_dmap,type="arc",arc_height=0.5,ftype="off",legend=FALSE,lwd=1)
add.color.bar(125,palm_dmap$cols,title="probability leaf armature present",
  lwd=8,outline=TRUE,prompt=FALSE,x=-0.15*par()$usr[2],y=par()$usr[4]/15,
  subtitle="125 my",fsize=0.9)
mtext("a)",line=-1.5,adj=0.08)
dd<-density(palm_smap)
par(mar=c(5.1,4.1,2.1,1.1))
plot(dd,transition=dd$trans[1],colors="black",alpha=1)
mtext("b)",line=1,adj=0)
plot(dd,transition=dd$trans[2],colors=grey(0.8),alpha=1)
mtext("c)",line=1,adj=0)
```

# Continuous characters

## The Brownian motion model

The standard model employed to study the evolution of continuous traits, as well as (especially) to reconstruct their ancestral values, is one called the Brownian motion model [@Felsenstein1973-a; @Felsenstein1985; @OMeara2006; @Harmon2019-book]. Brownian motion is a continuous time, directionless, random walk model [@Harmon2019-book; @Revell2022-book]. Under Brownian motion, successive evolutionary changes are independent and come from a Gaussian distribution with mean of 0 and variance of $\sigma^2 \times t$, in which $\sigma^2$ is the instantaneous rate of the Gaussian process and $t$ is the elapsed time [@Harmon2019-book]. Figure 9 shows a simulation of Brownian motion\footnote{Technically to create the visualization I discretized the depth of the tree into 200 units making this a discrete-time random walk, but the effect is the same.} evolution (Figure 9b) on the same simplified phylogenetic tree of three taxa that we saw earlier in the chapter (e.g., Figure 1), but in which I have re-colored the edges with different shades of gray (Figure 9a) so that they can be matched more easily with the Brownian trait evolution scenario (Figure 9b).

```{r fig9, echo=FALSE, fig.width=8, fig.height=4, dpi=300, fig.cap="(a) Three-taxon phylogenetic tree of Figure 1, but in which each edge of the tree has been plotted with a different color. (b) Single illustrative realization of Brownian motion evolution on the tree of figure panel (a). See main text for more details.", out.width = "100%"}
set.seed(77)
tree<-read.tree(text="(C:0.7,(B:0.3,A:0.3):0.4);")
tt<-make.era.map(tree,seq(0,0.7,length.out=200))
tt<-map.to.singleton(tt)
x<-fastBM(tt,a=1,sig2=0.5,internal=TRUE)
par(mfrow=c(1,2))
mapped<-paintBranches(tree,edge=1,"1")
mapped<-paintBranches(mapped,edge=5,"2")
mapped<-paintBranches(mapped,edge=2,"3")
mapped<-paintBranches(mapped,edge=3,"4")
cols<-setNames(c("black",grey(1),grey(0.75),grey(0.25)),
  1:4)
plot(mapped,cols,ftype="i",offset=0.2,fsize=1.2,xlim=c(0,0.95),
  ylim=c(1,3.2),mar=c(5.1,2.1,2.1,0.1),lwd=2,split.vertical=TRUE,
  outline=TRUE)
mtext("a)",adj=0)
pp<-get("last_plot.phylo",envir=.PlotPhyloEnv)
points(pp$xx[4:5],pp$yy[4:5],pch=21,cex=2,bg="white")
text(1.1*pp$xx[1:3],pp$yy[1:3],round(x[1:3],2),pos=4)
## points(pp$xx[4:5],pp$yy[4:5],pch=16,cex=2,col="black")
text(pp$xx[4]+0.07,pp$yy[4]-0.05,"root",font=3)
text(pp$xx[5],pp$yy[5]-0.15,"internal",font=3,pos=2)
## points(rep(0.7,3),1:3,pch=22,cex=2.5,bg=c("white","white","black"))
text(0.35,1.1,expression(paste('t'[C]," = 0.7")),cex=0.8)
text(0.2,2.6,expression(paste('t'[AB]," = 0.4")),cex=0.8)
text(0.55,2.1,expression(paste('t'[B]," = 0.3")),cex=0.8)
text(0.55,3.1,expression(paste('t'[A]," = 0.3")),cex=0.8)
par(mar=c(5.1,2.1,2.1,0.1))
phenogram(tt,x,lwd=4,ftype="i",fsize=1.2,
  spread.labels=FALSE,col="black",las=1,cex.axis=0.8,
  xlim=c(0,0.95),xlab="")
mtext("time",1,line=2.5,at=0.35)
clip(-0.1,0.7,min(x),max(x))
grid()
pathA<-c(3,phangorn::Ancestors(tt,3,"all"))
pathB<-c(2,phangorn::Ancestors(tt,2,"all"))
pathAB<-c(findMRCA(tt,c("A","B")),
  phangorn::Ancestors(tt,findMRCA(tt,c("A","B")),"all"))
pathC<-c(1,phangorn::Ancestors(tt,1,"all"))
tt<-paintBranches(tt,intersect(tt$edge[,2],pathC),"1")
tt<-paintBranches(tt,intersect(tt$edge[,2],pathB),"3")
tt<-paintBranches(tt,intersect(tt$edge[,2],pathA),"4")
tt<-paintBranches(tt,intersect(tt$edge[,2],pathAB),"2")
phenogram(tt,x,colors=cols,add=TRUE,col="white",lwd=2)
mtext("b)",adj=0)
```

Brownian motion evolution will produce a realized trait vector of phenotypic values among species that has an expected value ($\text{E}[x]$) equal to the root state ($x_0$), and a multivariate normal distribution with variance equal to the total height of each tip above the root multiplied by the instantaneous Brownian rate, $\sigma^2$ [@OMeara2006]. In other words $\mathbf{x} \sim \mathit{MVN}(x_0,\sigma^2\mathbf{C})$ in which **C** is an $N \times N$ matrix (for *N* tips in the tree), where each *i*,*j*th element contains the height above the root of the most recent common ancestor of taxa *i* and *j*. This matrix, **C**, for our phylogeny of Figure 9a would be calculated as follows.

$$
\mathbf{C} = 
\begin{bNiceMatrix}[first-row,first-col]
& A & B & C \\
A & t_A + t_{AB} & t_{AB} & 0.0 \\
B & t_{AB} & t_B + t_{AB} & 0.0 \\
C & 0.0 & 0.0 & t_C
\end{bNiceMatrix} =
\begin{bNiceMatrix}[first-row,first-col]
& A & B & C \\
A & 0.7 & 0.4 & 0.0 \\
B & 0.4 & 0.7 & 0.0 \\
C & 0.0 & 0.0 & 0.7
\end{bNiceMatrix}
$$

To compute the probability density of a set of data ($\mathbf{x}$) at the tips of the tree for any particular value of $\sigma^2$ and $x_0$, we must evaluate the following density function.\footnote{If this expression seems familiar to some readers, they should not be surprised: it is just a typical multivariate normal probability density function!}

$$
P(\mathbf{x}) = \frac{\exp(-\frac{1}{2}[\mathbf{x}-x_0]'(\sigma^2\mathbf{C})^{-1}[\mathbf{x}-x_0])}{\sqrt{(2\pi)^N\times\det(\sigma^2\mathbf{C})}}
$$

Finding the set of values for $x_0$ and $\sigma^2$ that maximize the value of this expression would provide us with the Maximum Likelihood estimates of these model parameters [@OMeara2006; @Revell2022-book].

## Ancestral state estimation under Brownian motion

Under Brownian motion evolution of our trait, not only are the tips distributed as a multivariate normal random variable, so are the values of internal nodes [@Schluter1997; @Rohlf2001; @Revell2022-book]. To find those node values that maximize the probability of our tip data, **x**, we merely have to expand the matrix **C** to include one additional row and column for each (non-root) internal node of the tree. In our three-taxon phylogeny of Figure 9a there is only one such node (labeled "*internal*") and our matrix **C** thus looks as follows.

$$
\mathbf{C} = 
\begin{bNiceMatrix}[first-row,first-col]
& A & B & C & internal \\
A & t_A + t_{AB} & t_{AB} & 0.0 & t_{AB} \\
B & t_{AB} & t_B + t_{AB} & 0.0 & t_{AB} \\
C & 0.0 & 0.0 & t_C & 0.0 \\
internal & t_{AB} & t_{AB} & 0.0 & t_{AB}
\end{bNiceMatrix} =
\begin{bNiceMatrix}[first-row,first-col]
& A & B & C & internal \\
A & 0.7 & 0.4 & 0.0 & 0.4 \\
B & 0.4 & 0.7 & 0.0 & 0.4 \\
C & 0.0 & 0.0 & 0.7 & 0.0 \\
internal & 0.4 & 0.4 & 0.0 & 0.4
\end{bNiceMatrix}
$$

To find the set of ancestral states under Brownian motion that maximize the probability of our observed data (our ML states), we simply identify the internal node values and root state ($x_0$) that jointly maximize the probability of the tip data given our model. Figure 10 gives a log-likelihood surface for the ancestral values at the root node of the tree (on the *x*-axis) and the single internal node: showing the maximum likelihood values of $x_0$ and $x_\mathit{internal}$ to be 1.29 and 1.82, respectively. The figure also includes an illustrative course of numerical optimization on this likelihood surface, though this result would (of course) depend on our starting value and specific optimization routine (Figure 10).

```{r fig10, echo=FALSE, fig.width=5, fig.height=4, dpi=300, fig.cap="Log-likelihood surface for the numerical values of the root and internal nodes of the tree and phenotypic trait data of Figure 9. The grey line shows an illustration of numerical optimization on this surface which convergences to the Maximum Likelihood values of both node states. See main text for more details."}
library(mnormt)
C<-vcvPhylo(tree)
sig2<-0.5
lik<-function(par,x,C,sig2,quiet=TRUE){
  dmnorm(c(x,par[2]),mean=par[1],varcov=sig2*C,log=TRUE)
}
PAR<-matrix(NA,50,2)
for(i in 1:50){
  PAR[i,]<-optim(c(1,1),lik,x=x[tree$tip.label],C=C,
    sig2=sig2,quiet=FALSE,control=list(fnscale=-1,
      maxit=i))$par
}
fit<-optim(c(1,1),lik,x=x[tree$tip.label],C=C,
  sig2=sig2,quiet=FALSE,control=list(fnscale=-1))
x0<-seq(0.5,2,length.out=100) ## seq(0.9,1.7,length.out=100)
x1<-seq(1,2.5,length.out=100) ## seq(1.4,2.2,length.out=100)
## x1<-seq(0.8,2.2,length.out=100)
L<-matrix(0,length(x0),length(x1))
for(i in 1:length(x0)) for(j in 1:length(x1)) 
  L[i,j]<-lik(c(x0[i],x1[j]),x=x[tree$tip.label],C=C,sig2=sig2)
par(mar=c(5.1,4.1,2.1,2.1) )
levels<-pretty(range(L,finite=TRUE),20)
contour(x=x0,y=x1,z=L,levels=levels,las=1,bty="n",
  cex.axis=0.7,cex.lab=0.9,xlab="root node",ylab="internal node",
  method="edge") #,col=grey(abs(levels)/max(abs(levels))))
grid()
lines(PAR,cex=0.2,lwd=2,col="darkgrey")
points(PAR,pch=16,cex=0.7)
```

In practice, rapid algorithms have been identified to find the set of internal node values that maximize the probability density of the data under our model [e.g., @Rohlf2001]. In fact, @Rohlf2001 points out that the Maximum Likelihood ancestral state at any node *i* can be expressed as a simple weighted average of the tip taxa values, in which the set of weights ($\mathbf{w}_i$) is given by the following expression.

$$
\mathbf{w}_{i} = 
  \left(
    \left(
      \mathbf{1}'\mathbf{C}^{-1}\mathbf{1}
    \right)^{-1}\mathbf{1} + \mathbf{C}_{H_{i}O}
    \left(
      \mathbf{I}-\mathbf{C}^{-1}\mathbf{1}\mathbf{1}'
      \left(
        \mathbf{1}'\mathbf{C}^{-1}\mathbf{1}
      \right)^{-1}
    \right)
  \right)\mathbf{C}^{-1}
$$

Here, $\mathbf{I}$ is the identity matrix and $\mathbf{1}$ is a conformable vector of 1.0s [@Rohlf2001]. The only unfamiliar term, $\mathbf{C}_{H_{i}O}$ is the *i*th row of the $m \times N$ matrix ($\mathbf{C}_{HO}$) containing the height of the root of the most recent common ancestor of each *i*th internal node (in rows) and each *j*th tip (in columns). For our tree of Figure 9, the matrix $\mathbf{C}_{HO}$ would be as follows.

$$
\mathbf{C}_{HO} = 
\begin{bNiceMatrix}[first-row,first-col]
& A & B & C \\
root & 0.0 & 0.0 & 0.0 \\
internal & 0.4 & 0.4 & 0.0
\end{bNiceMatrix}
$$

If we apply the equation of @Rohlf2001 to our tree of Figure 9a, then we will obtain the following sets of weights.
```{r, echo=FALSE, results="hide", message=FALSE}
w<-matrix(NA,tree$Nnode,Ntip(tree))
C<-vcv(tree)
invC<-solve(C)
C_ho<-rbind(rep(0,Ntip(tree)),
  vcvPhylo(tree)[1:(tree$Nnode-1)+Ntip(tree),1:Ntip(tree)])
one<-matrix(1,Ntip(tree),1)
for(i in 1:tree$Nnode){
  w[i,]<-(rep(1/sum(invC),Ntip(tree))+C_ho[i,]%*%(diag(1,Ntip(tree))-
      invC%*%one%*%t(one)*(1/sum(invC))))%*%invC
}
w
```
$$
\mathbf{w} = 
\begin{bNiceMatrix}[first-row,first-col]
& A & B & C \\
root & 0.28 & 0.28 & 0.44 \\
internal & 0.44 & 0.44 & 0.12
\end{bNiceMatrix}
$$

Finally, using these weights and our original data of Figure 9, we will get the following two results for $x_{root}$ and $x_{internal}$, our estimated root and internal node states, respectively.
```{r, echo=FALSE, results="hide", message=FALSE}
x_root<-sum(w[1,]*x[tree$tip.label])
x_root
x_internal<-sum(w[2,]*x[tree$tip.label])
x_internal
```
$$
x_{root} = \mathbf{w}_{root}\mathbf{x}' = 0.28 \times 2.22 + 0.28 \times 1.82 + 0.44 \times 0.36 = 1.29
$$
$$
x_{internal} = \mathbf{w}_{internal}\mathbf{x}' = 0.44 \times 2.22 + 0.44 \times 1.82 + 0.12 \times 0.36 = 1.82
$$

Not by coincidence, these values are identical to the ones that we obtained by numerically maximizing the likelihood in Figure 10. Although we could imagine obtaining variances and confidence intervals for our ancestral state estimates from the curvature of the likelihood surface, @Rohlf2001 also provides more reliable and efficient analytic standard errors, which, in turn, have been implemented in widely-used software for ancestral state estimation of continuous traits [e.g., @Revell2024].

## Empirical examples

### Brownian motion: Environmental niche evolution in liolaemid lizards

To explore ancestral character estimation for continuous characters under Brownian motion, I began with a dataset of maximum environmental temperature in degrees Celsius for lizards of the South American family Liolaemidae derived from @Esquerr2019. With these data and phylogeny in hand, I proceeded to estimate ancestral states under a Brownian model of evolutionary change, and then projected the observed (at the tips) and reconstructed (along edges and at nodes) values onto the tree using a visualization method described in Revell [-@Revell2013; -@Revell2014].

Figure 11 shows the result of this analysis. Although the estimated ancestral value at the deepest nodes of the phylogeny are predictably intermediate,\footnote{After all, ancestral state estimates under the Brownian motion model are a simple weighted mean of the species trait values, as shown above.} the projection nonetheless reveals an interesting pattern of similarity in thermal environment [phylogenetic signal, @Blomberg2003; @Revell2024] between related species (Figure 11). The ancestral state reconstruction also helps us to see multiple shifts in environmental temperature distributed among the different major clades of the phylogeny (Figure 11).

```{r fig11, echo=FALSE, fig.width=9, fig.height=4.75, dpi=300, out.width = "100%", fig.cap="A phylogenetic tree of the Maximum Likelihood ancestral states (along edges) and observed values (at the tips) of maximum environmental temperature among lizards of the South American family Liolaemidae. See main text for more details."}
data("liolaemid.data")
data("liolaemid.tree")
liol.temp<-setNames(liolaemid.data$temperature,
  rownames(liolaemid.data))[liolaemid.tree$tip.label]
obj<-contMap(liolaemid.tree,liol.temp,plot=FALSE)
obj<-setMap(obj,c("white","black"))
plot(obj,direction="upwards",lwd=c(2,8),
  fsize=c(0.2,0.8),legend=30,leg.txt="temperature",type="arc",
  arc_height=0.5,outline=FALSE,offset=3)
```

### Brownian motion: Body size in the frog genus *Conraua*

In addition to environmental temperature in Liolaemidae (Figure 11), I also estimated ancestral states for overall body size\footnote{Reported as snout-to-vent length, or SVL (Blackburn et al. 2020).} for African frogs from the genus *Conraua*, known commonly as slippery [@Blackburn2020] or giant [@Channing2019] frogs. 

The *Conraua* frog clade includes the world's largest frog -- the Goliath frog, *Conraua goliath* -- making their evolutionary history of body size particularly interesting [@Blackburn2020]. The tree and data for this example derive from @Blackburn2020 and @Channing2019, respectively, and a similar ancestral state reconstruction analysis was undertaken by @Blackburn2020. 

To estimate node states in this group, I obtained maximum body size values of six species of *Conraua* frog [@Channing2019], along with a single representative value of 53 mm for the outgroup clade Petropedetidae [as in @Blackburn2020], although the latter has been left out of all plots. I transformed all values using the natural logarithm for estimation, and then back-transformed my estimates and their confidence limits to the linear scale for graphing.

Figure 12 shows two different visualizations of ancestral state estimates for *Conraua* frogs. First, Figure panel 12a uses a continuous color gradient (similar to that of Figure 11) mapped to the nodes and tips of the plotted tree. Figure 12b, by contrast, shows a projection of the tree into a phenotype space, called a 'traitgram' following Evans et al. [-@Evans2009; @Revell2013; @Revell2018]. Overlain grey polygons give the 95\% confidence intervals around estimated ancestral values. In both graphs, we see the dramatic shift to large body size in the lineage leading to the Goliath frog, *C. goliath* (Figure 12).

```{r fig12, echo=FALSE, fig.width=10, fig.height=5, dpi=300, out.width = "100%", fig.cap="Ancestral state reconstruction of body size in the \\emph{Conraua} frogs. (a) Projection of the observed (at the tips) or estimated (at nodes) ancestral values of body size in mm. (b) Traitgram projection of phylogenetic tree into trait space, based on the ancestral reconstruction. The superimposed grey polygons show 95\\% confidence limits around estimated values. See main text for more details."}
conraua_tree<-read.tree(file="data/conraua_phylogeny.tre")
conraua_data<-read.csv(file="data/conraua_svl.csv",row.names=1)
conraua_svl<-setNames(conraua_data[,1],rownames(conraua_data))
conraua_svl<-conraua_svl[conraua_tree$tip.label]
obj<-fastAnc(conraua_tree,log(conraua_svl),CI=TRUE)
pruned.tree<-drop.tip(conraua_tree,"Petropedetidae")
pruned.svl<-conraua_svl[-which(names(conraua_svl)=="Petropedetidae")]
a<-exp(obj$ace[-1])
names(a)<-1:pruned.tree$Nnode+Ntip(pruned.tree)
layout(matrix(c(1,2),1,2),widths=c(0.4,0.6))
cMap<-contMap(pruned.tree,pruned.svl,anc.states=a,plot=FALSE)
cMap<-setMap(cMap,grey(seq(1,0,length.out=100)))
plot(cMap,nodes_only=TRUE,cex=c(1.5,1.5),ftype="i",
  mar=c(5.1,1.1,3.1,1.1),fsize=0.8,xlim=c(0,30),
  ylim=c(1,6.8),legend=FALSE)
add.color.bar(14,cMap$cols,title="body size (mm)",lims=cMap$lims,
  prompt=FALSE,lwd=6,x=0,y=6.5,subtitle="",fsize=0.8)
mtext("a)",adj=0,line=1)
par(mar=c(5.1,4.1,3.1,1.1),lend=1)
phenogram(pruned.tree,c(pruned.svl,a),las=1,xlab="",
  ylab="",axes=FALSE,ftype="i",fsize=0.7,spread.cost=c(0,1),
  label.pos=pruned.svl+c(5,-5.75,-7.5,5,0,-2),lwd=1,ylim=c(50,390))
axis(1,at=seq(max(nodeHeights(pruned.tree)),0,by=-5),
  labels=seq(0,max(nodeHeights(pruned.tree)),by=5),
  cex.axis=0.7)
axis(2,cex.axis=0.7,las=1)
title(ylab="body size (mm)",cex.lab=0.8)
mtext("time (mybp)",1,line=2,at=9,cex=0.8)
pp<-get("last_plot.phylo",envir=.PlotPhyloEnv)
ci<-rbind(cbind(pruned.svl,pruned.svl),exp(obj$CI95[2:nrow(obj$CI95),]))
legend("topleft",
  c("observed or reconstructed value","95% confidence interval"),
  col=c("black",make.transparent("grey",0.5)),
  lwd=c(1,NA),pch=c(NA,15),pt.cex=c(NA,2),cex=0.7,bty="n",inset=0.02)
for(i in 1:nrow(pruned.tree$edge)){
  xx<-c(pp$xx[pruned.tree$edge[i,]],pp$xx[pruned.tree$edge[i,2:1]])
  yy<-c(ci[pruned.tree$edge[i,],1],ci[pruned.tree$edge[i,2:1],2])
  polygon(xx,yy,col=make.transparent("grey",0.2),border=FALSE)
}
phenogram(pruned.tree,c(pruned.svl,a),add=TRUE,ftype="off",lwd=1)
mtext("b)",adj=0,line=1)
```

# Properties of ancestral state estimation

Though relentlessly popular, ancestral character estimation has been subject to numerous criticisms over the years [e.g., @Cunningham1998; @Cunningham1999; @Omland1999; @Losos2011; @Gascuel2020]. These critiques have assumed (very roughly) two flavors. On the one hand, ancestral state estimates, particularly for nodes close to the root of the tree, tend to have broad uncertainty. Indeed, @Ane2008 shows that the effective sample size\footnote{A measure the amount of independent information contained by the data.} for our estimate of the root node of the tree under Brownian motion tends to be much smaller than the number of tips, and perhaps as small as 5 or 6 for trees containing dozens of terminal taxa, or more [@Ane2008]. Similarly, @Gascuel2020 point out a paradox, or tradeoff, between the conditions under which we can estimate the state at the root of the tree for a discretely-valued trait, and the conditions under which the rates of change between character levels are estimable -- a phenomenon they denominate the 'Darwinian uncertainty principle.'\footnote{In short, when the rate of evolution is low, relatively few changes of the trait will have accrued and deep ancestral conditions are straightforward to estimate. On the other hand, these few changes of the trait will have provided little information about the rate of change between character levels. When the rate of change between states is high, on the other hand, precisely the converse will be true. See Gascuel and Steel (2020) for more details.}

Observing that the confidence intervals around ancestral states are broad is not the same as arguing that they are wrong, however: it's merely a reminder that phylogenetic comparative methods are ordinary statistical methods too [@Revell2018; @Revell2022-book]. As such, it would be incorrect to treat an estimated ancestral state as if it were a quantity known without error [@Losos2011]. Indeed, when the our underlying model assumptions are valid, ancestral state estimation has suitable statistical properties [@Revell2022-book].

A more pernicious problem arises when the model is wrong [@Revell2022-book].\footnote{Or, rather `badly wrong' -- seeing how, in point of fact, all models are wrong, even if many are useful (to paraphrase the statistician George Box).} Under these circumstances, it becomes possible to *confidently* estimate wrong ancestral node states.\footnote{This, too, one could argue, falls into the category of ancestral state reconstruction behaving as do all normal statistical methods! On the other hand, some evidence suggests that ancestral reconstruction is particularly sensitive to model assumption violations.}

To investigate ancestral state estimation when model assumptions are violated, I'll consider two different case studies: discrete character evolution under the hidden-rates model [@Beaulieu2013]; and bounded Brownian evolution [@Boucher2016]. I will show that when an incorrect model is used (specifically, a homogenous-rate M*k* model for the former data and unbounded Brownian motion for the latter), bad statistical behavior emerges. On the other hand, however, I will also show that this effect is substantively diminished under the correct, generating model for each case.

## Ancestral state estimation when the model is right

Before showing that ancestral state estimation can misbehave when the model of evolution is *wrong*, it seems useful to undertake a very brief exploration of the properties of ancestral state reconstruction when the model used for estimation fully captures the generating evolutionary process: in other words, when the model is "right." This is genuinely the best case scenario for ancestral character estimation, so we might expect to find statistical properties are optimal in this scenario.

To begin with, I simulated 100 stochastic, pure-birth phylogenies, each containing a total of 501 taxa (and thus 500 internal nodes), with a total root to tip height of 10.0.\footnote{This tree depth has no particular meaning. By trial and error I discovered that it tended to result in a relatively even distribution of marginal scaled likelihoods across simulations.} I next generated one binary (0/1) character and one continuous character for each tree. The discrete character was simulated with a generating value of **Q** that matched the illustrative value of **Q** used earlier in the chapter.

$$\mathbf{Q} = \begin{bmatrix}-q_{0,1} & q_{0,1} \\ q_{1,0} & -q_{1,0}\end{bmatrix} = \begin{bmatrix}-0.2 & 0.2\\ 0.2 & -0.2\end{bmatrix}$$

In addition to this discretely-valued character, I also simulated one continuous trait for each tree was simulated using a starting value of $x_0 = 0.0$ and a Brownian motion (stochastic diffusion) rate of $\sigma^2 = 1.0$.

```{r, echo=FALSE, eval=FALSE}
## load packages
library(doParallel)
library(foreach)
## set seed and simulation conditions
set.seed(99)
ntaxa<-501
nsim<-100
## make cluster
ncores<-min(nsim,detectCores()-1)
mc<-makeCluster(ncores,type="PSOCK")
registerDoParallel(cl=mc)
## simulation
Q<-matrix(c(-0.2,0.2,0.2,-0.2),2,2,
  dimnames=list(0:1,0:1))
sig2<-1.0
y0<-0.0
trees<-pbtree(n=ntaxa,scale=10,nsim=nsim)
x<-lapply(trees,sim.Mk,Q=Q,internal=TRUE)
y<-lapply(trees,fastBM,internal=TRUE)
fits_x<-foreach(i=1:nsim)%dopar%{
  phytools::fitMk(trees[[i]],x=x[[i]][1:ntaxa],
    model="ER",lik.func="pruning")
}
anc_x<-foreach(i=1:nsim)%dopar%{
  phytools::ancr(fits_x[[i]])
}
asr_x<-data.frame(
  bin=seq(0.01,0.99,by=0.02),
  count=rep(0,50),
  actual=rep(0,50),
  prop=rep(0,50))
for(i in 1:nsim){
  for(j in 1:nrow(asr_x)){
    ii<-intersect(which(anc_x[[i]]$ace[,2]>=(asr_x[j,1]-0.01)),
      which(anc_x[[i]]$ace[,2]<=(asr_x[j,1]+0.01)))
    asr_x[j,"count"]<-asr_x[j,"count"]+length(ii)
    asr_x[j,"actual"]<-asr_x[j,"actual"]+sum(x[[i]][ntaxa+ii]==1)
  }
}
asr_x[,"prop"]<-asr_x[,"actual"]/asr_x[,"count"]
asr_x[is.nan(asr_x[,"prop"]),"prop"]<-0
asr_y<-foreach(i=1:nsim)%dopar%{
  phytools::fastAnc(trees[[i]],y[[i]][1:ntaxa],CI=TRUE)
}
a<-mapply(function(t,x) x[1:t$Nnode+Ntip(t)],x=y,t=trees,
  SIMPLIFY=FALSE)
foo<-function(obj,a){
  sum(mapply('&&',a>=obj$CI95[,1],a<=obj$CI95[,2]))/length(a)
}
onCI<-mapply(foo,obj=asr_y,a=a,SIMPLIFY=TRUE)
stopCluster(mc)
save(trees,asr_x,asr_y,onCI,file="data/asr-simulation-1.rda")
```
```{r fig13, echo=FALSE, fig.width=10, fig.height=5.5, dpi=300, out.width = "100%", fig.cap="Accuracy of ancestral state reconstruction of discrete (a) and continuous (b) characters when the model for estimation is correct. (a) Node marginal scaled likelihoods (of state \"1\") compared to the relative frequency that each node was in that condition. If the scaled likelihoods are an accurate measure of the true probability of that each node was in each character state, then these values should form a 1:1 line. Point diameters have been scaled by the natural logarithm of the sample size (number of nodes) for each bin. (b) Distribution of the relative frequency (from 100 simulations) in which the true ancestral value fell on the 95\\% confidence interval of each node estimate, averaged across all nodes by simulation. See main text for additional details."}
load("data/asr-simulation-1.rda")
nsim<-length(trees)
par(mfrow=c(1,2),mar=c(5.1,4.1,3.1,1.1))
plot(NA,xlim=c(0,1),ylim=c(0,1),
  las=1,cex.axis=0.7,cex.lab=0.8,bty="n",
  xlab="marginal scaled likelihoods (state \"1\")",
  ylab="relative frequency true state \"1\"")
lines(c(0,1),c(0,0),lty="dotted")
segments(x0=asr_x[,"bin"],y0=rep(0,nsim),
  x1=asr_x[,"bin"],y1=asr_x[,"prop"],col="grey")
points(asr_x[,c("bin","prop")],pch=21,
  cex=log(asr_x$count)/4,bg="white")
lines(c(0,1),c(0,1),lwd=2,col="black",lty="dashed")
points(asr_x[,c("bin","prop")],pch=21,
  cex=log(asr_x$count)/4,bg=make.transparent("grey",0.7))
legend("topleft",c("1:1 line",
  paste(c(min(asr_x$count),round(exp(mean(log(asr_x$count)))),
  max(asr_x$count)),"nodes")),lwd=c(2,NA,NA,NA),
  pch=c(NA,21,21,21),
  lty=c("dashed",NA,NA,NA),
  col=c("black","black","black","black"),
  pt.bg=c(NA,"grey","grey","grey"),
  pt.cex=round(c(NA,min(log(asr_x$count)/4),
    mean(log(asr_x$count)/4),
    max(log(asr_x$count)/4)),4),
  bty="n",inset=0.05,cex=0.8,y.intersp=1.5,
  seg.len=3)
h<-hist(onCI,breaks=seq(floor(min(onCI)*100)/100,1,by=0.008),
  plot=FALSE)
mtext("a)",adj=0,line=1)
h$counts<-h$counts/sum(h$counts)
plot(h,main="",axes=FALSE,xlab="fraction of estimates on 95% CI",
  ylab=paste("relative frequency from",nsim,"simulations"),
  cex.lab=0.8,ylim=c(0,1.25*max(h$counts)))
axis(1,cex.axis=0.7)
axis(2,las=1,cex.axis=0.7)
mtext("b)",adj=0,line=1)
```

To measure the performance of ancestral state reconstruction for discrete characters when the generating model was known and used for estimation, I first binned the marginal scaled likelihoods of the node being in condition "1" into 50 equal-sized intervals, each 0.02 units wide. For each bin, I then simply counted the number of nodes across all simulations whose true states were equal to "1". This count, divided by the *total* number of nodes in that bin, would be expected to be equal to the midpoint of the bin if the marginal scaled likelihoods genuinely correspond to a probability that the node is in each state, under the model. So, for instance, if the marginal scaled likelihood ban spanned 0.19 through 0.21, with a midpoint of 0.2, then we would expect to find that (on average) 20\% of nodes in this bin should be in condition "1" (and 80\% thus in condition "0"), and so on.\footnote{If I'm not mistaken, B. O'Meara originally suggested this to me as a procedure for measuring the accuracy of a statistical method designed to compute probabilities during the \emph{Evolution} conference some years ago now.}

To measure the performance of ancestral state estimation when the generating model was known for continuous characters, I simply quantified the fraction of node-wise 95\% confidence intervals for which the true value fell within the interval.\footnote{I could have also measured the correlation between the generating and estimated values, or the average difference (bias) between the known values and the estimates.}

Figure 13 summarizes the results of this analysis. In Figure 13a, we see that the relative frequency of being in condition ``1'' closely tracks the marginal scaled likelihoods. In Figure 13b, we likewise see that the distribution of true node values that fall on the 95\%, averaged by simulation, is centered closely on 95\%, with a mean of 94.98\% and a range of $[0.916, 0.976]$ (Figure 13). In summary, when the model for estimation is *correct*, ancestral state reconstruction can work precisely as intended.

## Ancestral state estimation when the model is wrong

In the previous section, I illustrated how ancestral state reconstruction can be statistically well-behaved when the model for estimation is correct. Using a pair of very simple examples, I'll now try to demonstrate how ancestral character estimation might go astray when the model for estimation is badly wrong. I'll do this by simulating data under two different trait evolution models that we haven't yet discussed: one for discrete characters; and a second for continuous traits. Note that the purpose of this section is not to prove that we can recover the good statistical behavior of ancestral state reconstruction when the *correct* model is used, though that is sometimes true and will be true in this particular cases. To the contrary, my intention is to highlight the substantial sensitivity or vulnerability to model assumption violations of our standard reconstruction methods.

### Ancestral states under a hidden-rates model

To show this, I'll first use a model called the hidden-rates model [@Marazzi2012; @Beaulieu2013; @Revell2022-book; @Revell2024]. The hidden-rates model is one in which, for each observed level of a discrete trait, there might be one or more unobserved conditions, each with their own rates of transition of the observed state. Figure 14 illustrates evolution under a flavor of the hidden-rates model in which the observed condition "1" has two hidden levels: "1" in which the trait can still transition back to the "0" form; and "1\*" in which it cannot.\footnote{The character codndition of ``1*'' is also then an `absorbing' state for the character.} An attribute of trait evolution under the hidden-rates model is heterogeneity in the rate of transition between states. This is apparent in Figure 14b and 14c in which we see that transitions occur frequently between the two visible conditions of the trait, "0" and "1", until the condition "1" changes to the hidden state "1\*" (Figure 14). It's relatively easy to imagine a trait that could evolve in this way. Considering parity mode in squamate reptiles, for instance, perhaps when viviparity (which, in some squamates might be called `ovoviviparity' and is little more than egg retention through hatching), has recently evolved, it can still be lost. Over time, however, additional adaptations or loss of function mutations accumulate and viviparity eventually evolves into a condition from which oviparity can no longer re-evolve. This evolutionary scenario would be well-captured by the model illustrated in Figure 14. 

```{r fig14, echo=FALSE, fig.width=10, fig.height=5, dpi=300, out.width = "100%", fig.cap="A graphical illustration of the hidden rates model. (a) The structure of a hidden-rates model with one hidden, absorbing condition (``1*'') of the observed level ``1''. (b) Simulated evolution with both hidden levels of ``1'' shown. (c) Simulated history from (b), but with the two levels of ``1'' merged into a single, observed trait. See main text for more details."}
set.seed(13)
set.seed(13)
tree<-pbtree(n=101,scale=10)
layout(matrix(c(1,2,3),3,1),heights=c(0.25,0.375,0.375))
par(mar=c(0.1,2.1,2.1,0.1))
plot(NA,xlim=c(0,1),ylim=c(0,1),bty="n",axes=FALSE)
mtext("a)",adj=0)
plotrix::draw.circle(x=0.1,y=0.5,radius=0.05,nv=200,col="white")
plotrix::draw.circle(x=0.5,y=0.5,radius=0.05,nv=200,col="#595959")
plotrix::draw.circle(x=0.9,y=0.5,radius=0.05,nv=200,col="black")
text(0.1,0.5,"0",cex=2)
text(0.5,0.5,"1",cex=2,col="white")
text(0.9,0.5,"1*",cex=2,col="white")
arrows(x0=0.16,y0=0.55,x1=0.44,y1=0.55,lwd=3,length=0.1)
arrows(x1=0.16,y0=0.45,x0=0.44,y1=0.45,lwd=3,length=0.1)
arrows(x0=0.56,y0=0.5,x1=0.84,y1=0.5,lwd=3,length=0.1)
tol<-1e-12
Q<-matrix(c(
  -0.2, 0.2, 0.0,
  0.2,-0.3, 0.1,
  0.0, tol, -tol),3,3,byrow=TRUE,
  dimnames=list(c("0","1","1*"),c("0","1","1*")))
x<-sim.history(tree,Q,anc="0",message=FALSE)
cols<-setNames(c("white","#595959","black"),c("0","1","1*"))
plot(x,cols,direction="upwards",ftype="off",outline=TRUE,
  mar=c(0.1,2.1,2.1,0.1),lwd=3)
mtext("b)",adj=0)
xx<-mergeMappedStates(x,c("1","1*"),"1")
cols<-setNames(c("white","#595959"),c("0","1"))
plot(xx,cols,direction="upwards",ftype="off",outline=TRUE,
  mar=c(0.1,2.1,2.1,0.1),lwd=3)
mtext("c)",adj=0)
```

To simulate under this model I used the following transition matrix, **Q**, between observed and unobserved levels of each of the two trait conditions.

$$
\mathbf{Q} = 
\begin{bNiceMatrix}[first-row,first-col]
& 0 & 1 & 1* \\
0 & -0.20 & 0.20 & 0.00 \\
1 & 0.20 & -0.30 & 0.10 \\
1* & 0.00 & 0.00 & 0.00
\end{bNiceMatrix}
$$

I used the same one hundred, 501 taxon phylogenies that were simulated for the previous section. After simulation, I merged the two different hidden levels of character "1" (that is, "1" and "1\*") into a single, observed character condition.\footnote{This is because in empirical studies the `hidden' level of character ``1'' and its unhidden condition are the same observed state!} Finally, as opposed to estimating ancestral states under the correct model, I began by using an incorrect model of evolution without hidden states, but in which the back-and-forth transition rates between the two observed character conditions were allowed to occur with different rhythms.

```{r, echo=FALSE, eval=FALSE}
set.seed(99)
ntaxa<-501
nsim<-100
## make cluster
ncores<-min(nsim,detectCores()-1)
mc<-makeCluster(ncores,type="PSOCK")
registerDoParallel(cl=mc)
Q<-matrix(c(
  -0.2, 0.2, 0.0,
  0.2,-0.3, 0.1,
  0.0, 0.0, 0.0),3,3,byrow=TRUE,
  dimnames=list(c("0","1","1*"),c("0","1","1*")))
foo<-function(tree,Q){
  x<-sim.Mk(tree,Q,internal=TRUE,anc="0")
  while(("0"%in%as.character(x[tree$tip.label]))==FALSE)
    x<-sim.Mk(tree,Q,internal=TRUE,anc="0")
  x
}
x<-lapply(trees,foo,Q=Q)
foo<-function(x){
  y<-as.character(x)
  y[y=="1*"]<-"1"
  setNames(as.factor(y),names(x))
}
x.obs<-lapply(x,foo)
fits_x<-foreach(i=1:nsim)%dopar%{
  phytools::fitMk(trees[[i]],x[[i]][1:ntaxa],model="ARD")
}
anc_x<-lapply(fits_x,ancr)
asr_x<-data.frame(
  bin=seq(0.01,0.99,by=0.02),
  count=rep(0,50),
  actual=rep(0,50),
  prop=rep(0,50))
for(i in 1:nsim){
  for(j in 1:nrow(asr_x)){
    ii<-intersect(which(anc_x[[i]]$ace[,2]>=(asr_x[j,1]-0.01)),
      which(anc_x[[i]]$ace[,2]<=(asr_x[j,1]+0.01)))
    asr_x[j,"count"]<-asr_x[j,"count"]+length(ii)
    asr_x[j,"actual"]<-asr_x[j,"actual"]+sum(x.obs[[i]][ntaxa+ii]==1)
  }
}
asr_x[,"prop"]<-asr_x[,"actual"]/asr_x[,"count"]
asr_x[is.nan(asr_x[,"prop"]),"prop"]<-0
stopCluster(mc)
save(trees,x,fits_x,anc_x,asr_x,file="data/asr-hrm.rda")
```
```{r, echo=FALSE, eval=FALSE}
load("data/asr-hrm.rda")
fits_x.hrm<-mapply(function(t,x) fitHRM(t,x[t$tip.label],
  ncat=c(1,2),parallel=TRUE),t=trees,x=x.obs,SIMPLIFY=FALSE)
anc_x.hrm<-lapply(fits_x.hrm,ancr)
anc_x.hidden<-lapply(anc_x.hrm,hide.hidden)
asr_x.hrm<-data.frame(
  bin=seq(0.01,0.99,by=0.02),
  count=rep(0,50),
  actual=rep(0,50),
  prop=rep(0,50))
for(i in 1:nsim){
  for(j in 1:nrow(asr_x.hrm)){
    ii<-intersect(which(anc_x.hidden[[i]][,2]>=(asr_x.hrm[j,1]-0.01)),
      which(anc_x.hidden[[i]][,2]<=(asr_x.hrm[j,1]+0.01)))
    asr_x.hrm[j,"count"]<-asr_x.hrm[j,"count"]+length(ii)
    asr_x.hrm[j,"actual"]<-asr_x.hrm[j,"actual"]+sum(x.obs[[i]][ntaxa+ii]==1)
  }
}
asr_x.hrm[,"prop"]<-asr_x.hrm[,"actual"]/asr_x.hrm[,"count"]
asr_x.hrm[is.nan(asr_x.hrm[,"prop"]),"prop"]<-0
save(trees,x,fits_x,anc_x,asr_x,fits_x.hrm,anc_x.hrm,asr_x.hrm,file="data/asr-hrm.rda")
```
```{r fig15, echo=FALSE, fig.width=10, fig.height=5.5, dpi=300, out.width = "100%", fig.cap="Accuracy of ancestral state reconstruction of discrete characters when the hidden rate model of Figure 14 was used for simulation. (a) Node marginal scaled likelihoods (of state ``1'') compared to the relative frequency that each node was in that condition using a standard M\\emph{k} model for estimation. (b) The same as (a), but in which the generating hidden-rates model was used. If the scaled likelihoods are an accurate measure of the true probability of that each node was in each character state, then these values should form a 1:1 line. Point diameters have been scaled by the natural logarithm of the sample size (number of nodes) for each bin.  See main text for additional details."}
load("data/asr-hrm.rda")
par(mfrow=c(1,2),mar=c(5.1,4.1,3.1,1.1))
plot(NA,xlim=c(0,1),ylim=c(0,1),
  las=1,cex.axis=0.7,cex.lab=0.8,bty="n",
  xlab="marginal scaled likelihoods (state \"1\")",
  ylab="relative frequency true state \"1\"")
lines(c(0,1),c(0,0),lty="dotted")
segments(x0=asr_x[,"bin"],y0=rep(0,nsim),
  x1=asr_x[,"bin"],y1=asr_x[,"prop"],col="grey")
points(asr_x[,c("bin","prop")],pch=21,
  cex=log(asr_x$count)/4,bg="white")
lines(c(0,1),c(0,1),lwd=2,col="black",lty="dashed")
points(asr_x[,c("bin","prop")],pch=21,
  cex=log(asr_x$count)/4,bg=make.transparent("grey",0.7))
legend("topleft",c("1:1 line",
  paste(c(min(asr_x$count),round(exp(mean(log(asr_x$count)))),
  max(asr_x$count)),"nodes")),lwd=c(2,NA,NA,NA),
  pch=c(NA,21,21,21),
  lty=c("dashed",NA,NA,NA),
  col=c("black","black","black","black"),
  pt.bg=c(NA,"grey","grey","grey"),
  pt.cex=round(c(NA,min(log(asr_x$count)/4),
    mean(log(asr_x$count)/4),
    max(log(asr_x$count)/4)),4),
  bty="n",inset=0.05,cex=0.8,y.intersp=1.5,
  seg.len=3)
mtext("a)",adj=0,line=1)
##
plot(NA,xlim=c(0,1),ylim=c(0,1),
  las=1,cex.axis=0.7,cex.lab=0.8,bty="n",
  xlab="marginal scaled likelihoods (state \"1\")",
  ylab="relative frequency true state \"1\"")
lines(c(0,1),c(0,0),lty="dotted")
segments(x0=asr_x.hrm[,"bin"],y0=rep(0,nsim),
  x1=asr_x.hrm[,"bin"],y1=asr_x.hrm[,"prop"],col="grey")
points(asr_x.hrm[,c("bin","prop")],pch=21,
  cex=log(asr_x.hrm$count)/4,bg="white")
lines(c(0,1),c(0,1),lwd=2,col="black",lty="dashed")
points(asr_x.hrm[,c("bin","prop")],pch=21,
  cex=log(asr_x.hrm$count)/4,bg=make.transparent("grey",0.7))
legend("topleft",c("1:1 line",
  paste(c(min(asr_x.hrm$count),round(exp(mean(log(asr_x.hrm$count)))),
  max(asr_x.hrm$count)),"nodes")),lwd=c(2,NA,NA,NA),
  pch=c(NA,21,21,21),
  lty=c("dashed",NA,NA,NA),
  col=c("black","black","black","black"),
  pt.bg=c(NA,"grey","grey","grey"),
  pt.cex=round(c(NA,min(log(asr_x.hrm$count)/4),
    mean(log(asr_x.hrm$count)/4),
    max(log(asr_x.hrm$count)/4)),4),
  bty="n",inset=0.05,cex=0.8,y.intersp=1.5,
  seg.len=3)
mtext("b)",adj=0,line=1)
```

The result from this analysis is given in Figure 15a. Even though most points fall on the 1:1 line, we also see a large fraction of nodes that are not resolved into one condition or the other, even though they have (known) true state "0" (Figure 15a).

In addition to simply reconstructing under the standard M*k* model, we also fit and estimated ancestral states using the hidden-rates model, which was the generating evolutionary scenario of our data. The results from this analysis are given in Figue 15b which more closely resembles panel a of Figure 13 (in which the true model was known and used for estimation) than it does Figure 15a. This suggests that good statistical properties of estimation are largely recovered when the correct model is used.

### Ancestral states under bounded Brownian motion

As discussed earlier in this chapter, the typical model for ancestral state reconstruction of continuous traits is one of unbounded Brownian motion evolution, also known as stochastic diffusion or a continuous time random walk. To investigate the sensitivity of continuous character ancestral state reconstruction to model misspecification, we first generated 100 datasets, one for each our 100 simulated 501 taxon trees of the previous two sections. In this case, however, our generating model is *bounded* Brownian evolutionary change, with $x_0 = 0.0$, $\sigma^2 = 1.0$, and upper and lower bounds of $[-2, 2]$. Bounded Brownian motion (with reflexive bounds) is just like standard Brownian motion, but in which whenever the boundary condition is reached, the evolutionary process reflects back into the bounded space [@Boucher2016]. 

Following simulation, we first reconstructed ancestral states under a standard (unbounded) Brownian model, and then under *bounded* Brownian evolution, the latter utilizing the method of @Boucher2016. We measured the statistical behavior of ancestral state estimation in the same way as in Figure 13b; however, since the true value of an estimated parameter might fall within the confidence interval of the estimate either because the estimate is accurate or because the confidence interval is wide, we *also* measured accuracy of ancestral estimates by calculating the correlation between the known generating values and the estimates for each simulation. The results of this analysis are given in Figure 16.

```{r, eval=FALSE, echo=FALSE}
## load packages
library(doParallel)
library(foreach)
set.seed(99)
ntaxa<-501
nsim<-100
## make cluster
ncores<-min(nsim,detectCores()-1)
mc<-makeCluster(ncores,type="PSOCK")
registerDoParallel(cl=mc)
y<-lapply(trees,fastBM,bounds=c(-2,2),internal=TRUE)
y.obs<-lapply(y,function(x,ntaxa) x[1:ntaxa],ntaxa=ntaxa)
anc_bm<-foreach(i=1:nsim)%dopar%{
  phytools::fastAnc(tree=trees[[i]],x=y.obs[[i]],CI=TRUE)
}
stopCluster(mc)
bounded_fits<-mapply(bounded_bm,tree=trees,x=y.obs,
  lims=lapply(y.obs,range),
  MoreArgs=list(lik.func="eigen",parallel=TRUE),
  SIMPLIFY=FALSE)
mc<-makeCluster(ncores,type="PSOCK")
registerDoParallel(cl=mc)
anc_bounded<-foreach(i=1:nsim)%dopar%{
  phytools::ancr(bounded_fits[[i]])
}
stopCluster(mc)
a<-lapply(y,function(x,ntaxa) x[-c(1:ntaxa)],ntaxa=ntaxa)
foo<-function(obj,a){
  sum(mapply('&&',a>=obj$CI95[,1],a<=obj$CI95[,2]))/length(a)
}
onCI.bm<-mapply(foo,obj=anc_bm,a=a,SIMPLIFY=TRUE)
onCI.bounded<-mapply(foo,obj=anc_bounded,a=a,SIMPLIFY=TRUE)
save(trees,y,y.obs,a,anc_bm,anc_bounded,
  bounded_fits,nsim,ntaxa,onCI.bm,onCI.bounded,
  file="data/asr-bounded.rda")
```
```{r fig16, echo=FALSE, fig.width=10, fig.height=5.5, dpi=300, out.width = "100%", fig.cap="Accuracy of ancestral state reconstruction of  continuous characters when data were simulated under Brownian motion evolution with reflexive bounds. (a) Frequency distribution of the fraction of nodes falling in within the 95\\% confidence interval of each node estimate, averaged across all nodes by simulation both when a standard Brownian model (grey) and bounded model (shading lines) was used for estimation. (b) Distribution of correlation between true and estimated ancestral states when the data were generated under bounded Brownian evolution, and either a standard Brownian motion model (grey) or bounded model (shading lines) was used for estimation. See main text for additional details."}
load("data/asr-bounded.rda")
nsim<-length(trees)
par(mfrow=c(1,2),mar=c(5.1,4.1,3.1,1.1))
h_bm<-hist(onCI.bm,
  breaks=seq(floor(min(c(onCI.bm,onCI.bounded))*100)/100,1,by=0.02),
  plot=FALSE)
h_bm$counts<-h_bm$counts/sum(h_bm$counts)
h_bounded<-hist(onCI.bounded,
  breaks=seq(floor(min(c(onCI.bm,onCI.bounded))*100)/100,1,by=0.02),
  plot=FALSE)
h_bounded$counts<-h_bounded$counts/sum(h_bounded$counts)
plot(NA,xlim=range(h_bm$mids),ylim=range(c(h_bm$counts,h_bounded$counts)),
  axes=FALSE,xlab="fraction of estimates on 95% CI",
  ylab=paste("relative frequency from",nsim,"simulations"))
xx<-yy<-vector()
for(i in 1:length(h_bm$counts)){
  xx<-c(xx,h_bm$breaks[0:1+i])
  yy<-c(yy,rep(h_bm$counts[i],2))
}
xx<-c(xx[1],xx,xx[length(xx)])
yy<-c(0,yy,0)
polygon(xx,yy,col="grey")
xx<-yy<-vector()
for(i in 1:length(h_bounded$counts)){
  xx<-c(xx,h_bounded$breaks[0:1+i])
  yy<-c(yy,rep(h_bounded$counts[i],2))
}
xx<-c(xx[1],xx,xx[length(xx)])
yy<-c(0,yy,0)
polygon(xx,yy,density=12,col="black")
axis(1,cex.axis=0.7)
axis(2,las=1,cex.axis=0.7)
legend("topleft",c("unbounded BM","bounded BM"),
  fill=c("grey",NA),density=c(NA,20),
  cex=0.8,bty="n")
mtext("a)",adj=0,line=1)
foo<-function(a,obj) cor(a,obj$ace)
r_bm<-mapply(foo,a=a,obj=anc_bm)
r_bounded<-mapply(foo,a=a,obj=anc_bounded)
h_bm<-hist(r_bm,
  breaks=seq(0.7,0.94,by=0.015),plot=FALSE)
h_bm$counts<-h_bm$counts/sum(h_bm$counts)
h_bounded<-hist(r_bounded,
  breaks=seq(0.7,0.94,by=0.015),plot=FALSE)
h_bounded$counts<-h_bounded$counts/sum(h_bounded$counts)
plot(NA,xlim=range(h_bm$mids),ylim=range(c(h_bm$counts,h_bounded$counts)),
  axes=FALSE,xlab="correlation between true and estimates states",
  ylab=paste("relative frequency from",nsim,"simulations"))
xx<-yy<-vector()
for(i in 1:length(h_bm$counts)){
  xx<-c(xx,h_bm$breaks[0:1+i])
  yy<-c(yy,rep(h_bm$counts[i],2))
}
xx<-c(xx[1],xx,xx[length(xx)])
yy<-c(0,yy,0)
polygon(xx,yy,col="grey")
xx<-yy<-vector()
for(i in 1:length(h_bounded$counts)){
  xx<-c(xx,h_bounded$breaks[0:1+i])
  yy<-c(yy,rep(h_bounded$counts[i],2))
}
xx<-c(xx[1],xx,xx[length(xx)])
yy<-c(0,yy,0)
polygon(xx,yy,density=12,col="black")
axis(1,cex.axis=0.7)
axis(2,las=1,cex.axis=0.7)
legend("topleft",c("unbounded BM","bounded BM"),
  fill=c("grey",NA),density=c(NA,20),
  cex=0.8,bty="n")
mtext("b)",adj=0,line=1)
```

We see that when data are simulated under bounded Brownian evolution, but unbounded Brownian motion is assumed as a model for estimation, confidence intervals are too narrow (Figure 16a), with a mean fraction of true ancestral states falling within the 95\% confidence intervals of the estimates of 80.8\% (range: $[71.6, 87.6]$; Figure 16a). By contrast, almost exactly 95\% of confidence intervals estimated under *bounded* Brownian evolution [@Boucher2016] included the true, generating values of the states (average: 94.6\%; range: $[92.0, 97.8]$; Figure 16a).

In addition to having the correct confidence intervals, estimates obtained under bounded Brownian motion were also more accurate (Figure 16b). The mean correlation between generating and estimated ancestral states when *unbounded* Brownian evolution was assumed as a model for estimation was $\bar{r} = 0.822$ -- compared to a mean of $\bar{r} = 0.843$ when the correct model was used (Figure 16b).

# A short note on implementation

Ancestral character estimation is implemented in the R statistical computing software [@RTeam2024] package *phytools* [@Revell2012; @Revell2024]. *phytools* in turn depends on the core R phylogenetics packages *ape* [@Paradis2019] and *phangorn* [@Schliep2011].

# Conclusions

Ancestral state reconstruction has long been among the most relentlessly popular analyses of phylogenetic comparative biology. In this chapter, I have tried to overview the theoretical and practical basics of ancestral state reconstruction for discrete and continuously-valued character traits. I have shown how ancestral state reconstruction can be applied to empirical datasets of various types, such as estimating the ancestral conditions of environmental temperature in liolaemid lizards, diel activity pattern in primates, or body size in frogs.

In spite of its popularity, ancestral state estimation has some limitations. In particular, ancestral node estimates often come associated with very broad confidence limits, deep in the phylogenetic tree. Additionally, ancestral state reconstruction can be highly sensitive to violations of the assumptions of the evolutionary model used for estimation. Though both of these attributes (broad confidence intervals when the amount of information about a parameter is low; and sensitivity to model assumptions) are properties of many statistical inference methods, enthusiasts of ancestral state reconstruction have sometimes failed to sufficiently appreciate the nature and depth of these limitations.

In an age when phylogenetic data is ever easier to produce, I have little doubt that the appeal of ancestral character state reconstruction will continue to grow into the future. I hope that this chapter will provide a helpful introductory guide to those biologists and scientists of other disciplines who dare to venture into this endeavor.

# References